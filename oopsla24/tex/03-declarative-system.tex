\label{sec:declarative-system}

The declarative system serves as a specification of the
type inference algorithm. It consists of two main parts:
the subtyping and the type inference. 

\subsection{Subtyping}
It is represented by a set of inference rules shown in
\cref{fig:declarative-subtyping}.

\begin{figure}[h]
  \begin{multicols}{2}
    \ottdefnDOneNsubLabeled{}

    \ottdefnDOnePsupLabeled{}
  \end{multicols}
  \hfill\\
  \begin{multicols}{2}
    \ottdefnDOneNeqLabeled{}

    \ottdefnDOnePeqLabeled{}
  \end{multicols}
  \caption{Declarative Subtyping}
  \label{fig:declarative-subtyping}
\end{figure}

\paragraph{Quantifiers}  
Symmetric rules \ruleref{\ottdruleDOneForallLabel} and 
\ruleref{\ottdruleDOneExistsLabel} specify 
the subtyping between top-level quantified types.
Usually, the polymorphic subtyping is represented by two rules
introducing quantifiers to the left and to the right-hand side of the subtyping.
For conciseness of representation, we compose these rules into one.
First, our rule extends context $[[Γ]]$ with the quantified variables 
from the right-hand side ($[[pbs]]$ or $[[nbs]]$), 
as these variables must remain abstract.
Second, it verifies that the left-hand side quantifiers
($[[pas]]$ or $[[nas]]$) can be instantiated to continue subtyping recursively. 

The instantiation of quantifiers is modeled by substitution $[[σ]]$.
The notation $[[Γ2 ⊢ σ : Γ1]]$ specifies its domain and range.
For instance, $[[Γ, pbs ⊢ σ : {pas}]]$ means that 
$[[σ]]$ maps the variables from $[[pas]]$ to (positive) types
well-formed in $[[Γ, pbs]]$.
This way, application $[[ [σ]iN ]]$ instantiates (replaces) every
$[[αi⁻]]$ in $[[iN]]$ with $[[σ]]([[αi⁻]])$.

\paragraph{Invariant Shifts}
An important restriction that we put on the subtyping system is
that the subtyping on shifted types requires their equivalence,
as shown in \ruleref{\ottdruleDOneShiftDLabel} and
\ruleref{\ottdruleDOneShiftULabel}. Relaxing both of these
invariants make the system equivalent to \systemf, 
and thus, undecidable. 
However, after certain changes 
\ruleref{\ottdruleDOneShiftULabel} can be relaxed to the covariant form,
thereby increasing the expressiveness of the system. These
changes are discussed in \cref{sec:weakening-invariant}.

\paragraph{Functions}
Standardly, the subtyping of function types is covariant in the return type
and contravariant in the argument type.

\paragraph{Variables}
The subtyping of variables is defined reflexively,
which is enough to ensure the reflexivity of subtyping in general.
The algorithm will use the fact that the subtypes of a variable 
coincide with its supertypes, which however is not true for an
arbitrary type.

\subsubsection{Properties of the Declarative Subtyping}
\label{sec:decl-subtyping-properties}

A property that is important for the subtyping algorithm, 
in particular for the type \emph{upgrade} procedure (\cref{sec:lub}),
is the preservation of free variables by subtyping.
Informally, it says that the free variables
of a positive type cannot disappear in its subtypes,
and the free variables of a negative type
cannot disappear in its supertypes.

\begin{property}[Subtyping Preserves Free Variables]
  \label{prop:subtyping-preserves-fv}
  Let us assume that all the mentioned types are well-formed in $[[Γ]]$. Then
  $[[Γ ⊢ iN1 ≤ iN2]]$ implies $[[fv(iN1) ⊆ fv(iN2)]]$,
  and $[[Γ ⊢ iP1 ≥ iP2]]$ implies $[[fv(iP1) ⊆ fv(iP2)]]$.
\end{property}

Another property that we extensively use is that the subtyping is reflexive and transitive,
and agrees with substitution.

\begin{property}[Subtyping forms a preorder]
  Let us say that two types $[[iN1]]$ and $[[iN2]]$ are in the subtyping relation if there 
  exists a context $[[Γ]]$ such that $[[Γ ⊢ iN1 ≤ iN2]]$;
  symmetrically, two types $[[iP1]]$ and $[[iP2]]$ are in the subtyping relation
  if there exists $[[Γ]]$ such that $[[G ⊢ iP2 ≥ iP1]]$.
  Then the subtyping relation defined this way is reflexive and transitive.
\end{property}

\begin{property}[Subtyping agrees with substitution]
  Suppose that  $[[σ]]$ is a substitution such that $[[Γ2 ⊢ σ : Γ1]]$. 
  Then
  \begin{enumerate}
    \item [$-$] $[[Γ1 ⊢ iN ≤ iM]]$ implies $[[Γ2 ⊢ [σ]iN ≤ [σ]iM]]$, and
    \item [$+$] $[[Γ1 ⊢ iP ≥ iQ]]$ implies $[[Γ2 ⊢ [σ]iP ≥ [σ]iQ]]$.
  \end{enumerate}
\end{property}

Moreover, any two \emph{positive} types have the least upper bound, which makes
the positive subtyping semilattice.
The positive least upper bound can be found algorithmically,
which we will discuss in the next section.

\begin{property}[Positive Least Upper Bound exists]
  Suppose that $[[iP1]]$ and $[[iP2]]$ are positive types
  well-formed in $[[Γ]]$.
  Then there exists the least common supertype--- a type $[[iP]]$ such that
  \begin{itemize}
    \item $[[Γ ⊢ iP ≥ iP1]]$ and $[[Γ ⊢ iP ≥ iP2]]$, and 
    \item for any $[[iQ]]$ such that $[[Γ ⊢ iQ ≥ iP1]]$ and $[[Γ ⊢ iQ ≥ iP2]]$,
      $[[Γ ⊢ iQ ≥ iP]]$.
  \end{itemize}
\end{property}

\paragraph{Negative Greatest Lower Bound does not exist}
However, the symmetric construction---the greatest lower bound of two negative types
does not always exist. Let us consider the following counterexample.
Let us consider the following types: 
\begin{itemize}
  \item $[[iN]]$ and $[[iQ]]$ are arbitrary closed types, 
  \item $[[iP]]$, $[[iP1]]$, and $[[iP2]]$ are non-equivalent closed types 
    such that $[[· ⊢ iP1 ≥ iP]]$ and $[[· ⊢ iP2 ≥ iP]]$, and 
    none of the types is equivalent to $[[iQ]]$.
\end{itemize}
What is the greatest common subtype of  
$[[iQ → ↓↑iQ → ↓↑iQ → iN]]$ and $[[iP → ↓↑iP1 → ↓↑iP2 → iN]]$?
One of the common subtypes is $[[∀α⁺,β⁺,γ⁺. α⁺ → ↓↑β⁺ → ↓↑γ⁺ → iN]]$,
which, however is not the greatest one.  

One can find two greater candidates:
$[[iM1 = ∀α⁺,β⁺. α⁺ → ↓↑α⁺ → ↓↑β⁺ → iN]]$ and $[[iM2 = ∀α⁺,β⁺. β⁺ → ↓↑α⁺ → ↓↑β⁺ → iN]]$.
Instantiating $[[α⁺]]$ and $[[β⁺]]$ with $[[iQ]]$ ensures 
that both of these types are subtypes of $[[iQ → ↓↑iQ → ↓↑iQ → iN]]$;
instantiating $[[α⁺]]$ with $[[iP1]]$ and $[[β⁺]]$ with $[[iP2]]$
demonstrates the subtyping with $[[iP → ↓↑iP1 → ↓↑iP2 → iN]]$,
as $[[iP]]$ is a subtype of both $[[iP1]]$ and $[[iP2]]$.

By analyzing the inference rules, we can prove that
both $[[iM1]]$ and $[[iM2]]$ are maximal common subtypes.
Since $[[iM1]]$ and $[[iM2]]$ are not equivalent,
it means that none of them is the greatest.


\subsection{Equivalence and Normalization}
\label{sec:decl-equivalence}

The subtyping relation forms a preorder on types,
and thus, it induces an equivalence relation \aka bicoercibility 
\cite{tiuryn1995:bicoercibility}.
The declarative specification of subtyping must be defined up to this equivalence.
Moreover, the algorithms we use must withstand changes in input types within the equivalence class.
To deal with non-trivial equivalence, 
we use normalization---a function that uniformly selects a representative of the equivalence class.

Using normalization gives us two benefits:
\begin{enumerate*}
  \item [(i)] we do not need to modify significantly standard operations such as unification to withstand non-trivial equivalence, and
  \item [(ii)] if the subtyping (and thus, the equivalence) changes, we only need to modify the normalization function, 
    while the rest of the algorithm remains the same.
\end{enumerate*}

In our system, equivalence is reacher than equality. Specifically,
\begin{enumerate}
  \item[(ii)] one can introduce redundant quantifiers. For example, $[[∀α⁺,β⁺.↑α⁺]]$ is equivalent
  but not equal to $[[∀α⁺.↑α⁺]]$;
  \item[(i)] one can reorder quantifiers. For example, $[[∀α⁺,β⁺.α⁺ → β⁺ → γ⁻]]$ is equivalent but not equal to
  $[[∀α⁺,β⁺.β⁺ → α⁺ → γ⁻]]$; 
  \item[(iii)] the transformations (i) and (ii) can happen at any
    position in the type.
\end{enumerate}

It turns out that the transformations (i-iii) are complete, 
in the sense that they generate the whole equivalence class.
This way, to normalize the type, one must
\begin{enumerate}
  \item [(i)] remove the redundant quantifiers,
  \item [(ii)] reorder the quantifiers to the canonical order,
  \item [(iii)] do the procedures (i) and (ii) recursively on the subterms.
\end{enumerate}

The normalization algorithm is shown in \cref{fig:type-nf}.
The steps (i-ii) are implemented by the \emph{ordering} function
$[[ord varset in iN]]$ and $[[ord varset in iP]]$.
For a set of variables $[[varset]]$, and a type, it 
returns a list of variables from $[[varset]]$ that occur in the type in 
the order of their first occurrence.
For brevity, we omit the formal definition of ordering,
referring the reader to the appendix.

\begin{figure}[h]
  
  \begin{multicols}{2}
  \ottdefnNrmNNormLabeled{}
  \\
  $[[ord varset in iN]]$ returns a list of variables
  $[[varset ∩ fv(iN)]]$ in the order of their first occurrence in $[[iN]]$
  \columnbreak\\
  \ottdefnNrmPNormLabeled{}
  \\
  $[[ord varset in iP]]$ returns a list of variables
  $[[varset ∩ fv(iP)]]$ in the order of their first occurrence in $[[iP]]$
  \end{multicols}


  \caption{Type Normalization Procedure} 
  \label{fig:type-nf}
\end{figure}


For the normalization procedure, 
we prove soundness and completeness \wrt the equivalence relation.
\begin{property}[Correctness of normalization]
  \hfill \\
  \begin{itemize}
    \item[$-$] For $[[iN]]$ and $[[iM]]$ well-formed in $[[Γ]]$,
  $[[Γ ⊢ iN ≈ iM]]$ is equivalent to $[[nf(iN) = nf(iM)]]$;
    \item[$+$] analogously, for $[[iP]]$ and $[[iQ]]$ well-formed in $[[Γ]]$,
  $[[Γ ⊢ iP ≈ iQ]]$ is equivalent to $[[nf(iP) = nf(iQ)]]$.
  \end{itemize}
\end{property}


\subsection{Type Inference}

The declarative specification of the type inference is shown in 
\cref{fig:declarative-inference}.
The positive typing judgment $[[Γ ; Φ ⊢ v : iP]]$ is read as 
``under the type context $[[Γ]]$ and variable context $[[Φ]]$,
the term $[[v]]$ is allowed to have the type $[[iP]]$'',
where $[[Φ]]$---the variable context---is defined standardly as
a set of pairs of the form $[[x : iP]]$. 
The negative typing judgment is read similarly.

The \emph{Application typing} judgment
infers the type of the application of a function to a list of arguments.
It has form of $[[Γ ; Φ ⊢ iN ● args ⇒> iM]]$, 
which reads ``under the type context $[[Γ]]$ and variable context $[[Φ]]$,
the application of a function of type $[[iN]]$ to the list of arguments $[[args]]$
is allowed to have the type $[[iM]]$''.

\begin{figure}[h]
  \ottdefnsDTLabeled
  \caption{Declarative Inference}
  \label{fig:declarative-inference}
\end{figure}

Let us discuss the rules of the declarative system in more detail.

\paragraph{Variables}
  Rule \ruleref{\ottdruleDTVarLabel} allows to infer
  the type of a variable from the context. 
  In literature can be found another version of this rule,
  that enables inferring a type \emph{equivalent}
  to the type from the context. 
  In our case, the inference of equivalent types
  is admissible in general case by \ruleref{\ottdruleDTPEquivLabel}.

\paragraph{Annotations}
  Subtyping is also used by the annotation rules \ruleref{\ottdruleDTNAnnotLabel}
  and \ruleref{\ottdruleDTPAnnotLabel}. The annotation is only valid if the
  inferred type is a subtype of the annotation type.


\paragraph{Abstractions}
  The typing of lambda abstraction is standard. 
  Rule \ruleref{\ottdruleDTtLamLabel} first checks
  that the given type annotating the argument is well-formed,
  and then infers the type of the body in the extended context.
  As a result, it returns an arrow type of function from the
  annotated type of the argument to the type of the body.
  Rule \ruleref{\ottdruleDTTLamLabel} infers polymorphic $[[∀]]$-type. 
  It extends the type context with the quantifying variable $[[pa]]$ and 
  infers the type of the body. As a result, it returns a polymorphic type
  quantifying the abstracted variable $[[pa]]$ over the type of the body.

\paragraph{Return and Thunk}
  Rules \ruleref{\ottdruleDTReturnLabel} 
  and \ruleref{\ottdruleDTThunkLabel}
  add the corresponding shifts to the type of the body.

\paragraph{Unpack}
  Rule \ruleref{\ottdruleDTUnpackLabel} types elimination of $[[∃]]$.
  First, it infers the normalized type of the existential package.
  The normalization is required to fix the order of the quantifying variables
  to bind them. Alternative approaches that do not require normalization
  will be discussed in \cref{sec:explicit-type-application}.
  After the bind, the rule infers the type of the body 
  and checks that it does not use the bound variables so that they do not 
  escape the scope.

\paragraph{Applicative Let Binders}
  Rules \ruleref{\ottdruleDTAppLetLabel} and \ruleref{\ottdruleDTAppLetAnnLabel}
  infer the type of the applicative let binders.
  Both of them infer the type of the head $[[v]]$ 
  and invoke the application typing to infer the type of the application 
  before recursing on the body of the let binder.

  The former rule infers the type of an \emph{unannotated} let binder, and thus
  it requires the resulting type of application to be \emph{the principal type},
  so that the type we assign to the bound variable $[[x]]$ is determined.
  In this context, principality means minimality. In other words, 
  $[[Γ ; Φ ⊢ iM ● args ⇒> ↑iQ principal]]$ means that
  any other type $[[iQ']]$ inferrable for the application (\ie $[[Γ ; Φ ⊢ iM ● args ⇒> ↑iQ']]$)
  is greater than the principal type $[[iQ]]$, \ie $[[Γ ⊢ iQ' ≥ iQ]]$.

  The latter rule is for the \emph{annotated} binder,
  and thus, the type of the bound $[[x]]$ is given, 
  however, the rule must check that this type is a
  a supertype of the inferred type of the application. 
  This check is done by invoking the subtyping judgment
  $[[Γ ⊢ ↑iQ ≤ ↑iP]]$.
  This judgment is more restrictive than checking bare 
  $[[Γ ⊢ iP ≥ iQ]]$, however, it is necessary
  to make the algorithm complete as it allows us to preserve
  certain invariants throughout the algorithm to ensure
  the decidability of the produced unification task.
  In \cref{sec:proof-subtyping}, we discuss these invariants in
  more detail, and in \cref{sec:weakening-invariant} we suggest 
  a way to relax them.

\paragraph{Typing up to Equivalence}
  As discussed in \cref{sec:decl-equivalence}, the subtyping, as a preorder, 
  induces a non-trivial equivalence relation on types. 
  The system must not distinguish between equivalent types,
  and thus, type inference must be defined up to equivalence. 
  For this purpose, we use rules \ruleref{\ottdruleDTPEquivLabel}  
  and \ruleref{\ottdruleDTNEquivLabel}.
  They allow one to replace the inferred type with an equivalent one.  

\paragraph{Application to an Empty List of Arguments}
  The base case of the application type inference is 
  represented by rule \ruleref{\ottdruleDTEmptyAppLabel}.
  If the head of the type $[[iN]]$ is applied to no arguments, 
  the type of the result is allowed to be $[[iN]]$ or any 
  equivalent type. We need to relax this rule up to equivalence
  to ensure the corresponding property globally:
  the inferred application type can be replaced with an equivalent one.
  Alternatively, we could have added a separate rule similar to 
  \ruleref{\ottdruleDTPEquivLabel}, however, 
  the local relaxation is sufficient to prove the global property.

\paragraph{Application of a Polymorphic Type $[[∀]]$}
  The complexity of the system is hidden in the rules, 
  whose output type is not immediately defined by their input
  and the output of their premises 
  (\aka not mode-correct \cite{dunfield2020:bidirectional}).
  In our typing system, such rule is \ruleref{\ottdruleDTForallAppLabel}: 
  the instantiation of the quantifying variables is
  not known a priori. The algorithm we present in \cref{sec:algorithm} 
  delays this instantiation until more information about it 
  (in particular, typing constraints) is collected.

  To ensure the priority of application between this rule and 
  \ruleref{\ottdruleDTEmptyAppLabel}, we also check that 
  the list of arguments is not empty.

\paragraph{Application of an Arrow Type}
  Another important application rule is \ruleref{\ottdruleDTArrowAppLabel}.
  This is where the subtyping is used to check that the type of the argument
  is convertible to (a subtype of) the type of the function parameter.
  In the algorithm (\cref{sec:algorithm}), this subtyping check will provide the constraints
  we need to resolve the delayed instantiations of the quantifying variables.

\subsubsection{Declarative Typing Properties}
  An important property that the declarative system has is
  that the declarative specification is correctly defined for
  equivalence classes.

\begin{property}[Declarative Typing is Defined up to Equivalence]
  Let us assume that $[[Γ ⊢ Φ1 ≈ Φ2]]$, \ie  
  the corresponding types assigned by $[[Φ1]]$ and
  $[[Φ2]]$ are equivalent in $[[Γ]]$.
  Also, let us assume that 
  $[[Γ ⊢ iN1 ≈ iN2]]$, $[[Γ ⊢ iP1 ≈ iP2]]$,
  and $[[Γ ⊢ iM1 ≈ iM2]]$. Then
  \begin{itemize}
    \item [$-$] $[[Γ ; Φ1 ⊢ c : iN1]]$ holds if and only if $[[Γ ; Φ2 ⊢ c : iN2]]$,
    \item [$+$] $[[Γ ; Φ1 ⊢ v : iP1]]$ holds if and only if $[[Γ ; Φ2 ⊢ v : iP2]]$, and
    \item [$\bullet$] $[[Γ; Φ1 ⊢ iN1 ● args ⇒> iM1]]$ holds if and only if $[[Γ; Φ2 ⊢ iN2 ● args ⇒> iM2]]$.
  \end{itemize}
\end{property}

\subsection{Relation to \systemf}
\label{sec:rel-to-systemf}

To establish a correspondence between \fexists and standard unpolarized \systemf,
we present a translation in both ways: the polarization from \systemf to \fexists
and the depolarization from \fexists to \systemf. 

\paragraph{Type-level Translation}

The type depolarization (\cref{fig:depolarization}) simply forgets the polarization structure of types:
it removes the shift operators and the polarities of the free type variables.

The type polarization (\cref{fig:polarization}) is more involved, as there are multiple
ways to polarize a type: for instance, a variable $[[α]]$ can be polarized to $[[α⁺]]$ or $[[α⁻]]$.
The choice of polarization affects the execution strategy of the program.
We chose the positive polarization: every \systemf type is translated to a \emph{positive} type of \fexists.
This choice makes it smoother to lift the translation to the term level, which will be disused next.

\begin{figure}[ht]
  \begin{minipage}[t]{0.65\linewidth}
    \centering
      \begin{minipage}[t]{0.32\linewidth}
      \ottfundefnunpolP{}
      \end{minipage}
      \begin{minipage}[t]{0.32\linewidth}
      \ottfundefnunpolN{}
      \end{minipage}
    \caption{Type Depolarization}
    \label{fig:depolarization}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}[t]{0.3\linewidth}
    \centering
    \ottfundefnpolarP{}
    \caption{Type Polarization}
    \label{fig:polarization}
  \end{minipage}
\end{figure}

\paragraph{Term-level Translation}

The term-level translations between systems are more complex.
They are defined as \emph{elaborations} of the typing derivations.
In other words, the input of the translation is not a term, 
but a whole typing derivation of this term in the corresponding system.
For brevity, we omit the formal definition of the term-level translation,
referring the reader to the appendix (\cref{sec:term-translation}). 

We prove the soundness of the translation (\cref{lemma:translation-soundness}),
which in particular guarantees that the translation preserves typing. 

\begin{property}[Soundness of the Translation]
    \label{lemma:translation-soundness}
    \begin{align*}
      & [[Γ ⊢ iN ≤ iM ⤳ ft]]  \text{ implies }  [[|Γ| ; · ⊢ ft : |iN| → |iM| ]], \\
      & [[Γ ⊢ iP ≥ iQ ⤳ ft]]  \text{ implies }  [[|Γ| ; · ⊢ ft : |iQ| → |iP| ]], \\
      & [[Γ; Φ ⊢ v : iP ⤳ ft]]  \text{ implies }  [[|Γ| ; |Φ| ⊢ ft : |iP|]], \\
      & [[Γ; Φ ⊢ c : iN ⤳ ft]] \text{ implies }  [[|Γ| ; |Φ| ⊢ ft : |iN|]], \\
      & [[fΓ ; fΦ ⊢ ft : fT ⤳ c]]  \text{ implies }  [[+|fΓ|+ ; +|fΦ|+ ⊢ c : ↑+|fT|+]].
    \end{align*}
\end{property}


% \begin{figure}[h]
%   \begin{equation*}
%   \begin{aligned}
%     [[|↓iN|]] &= [[|iN|]] \\
%     [[|↑iP|]] &= [[|iP|]] \\
%   \end{aligned}
%   \qquad
%   \begin{aligned}
%     [[|α±|]] &= [[a]] \\
%     [[|iP → iN|]] &= [[|iP| → |iN|]] \\
%   \end{aligned}
%   \qquad
%   \begin{aligned}
%     [[|∀α⁺.iN|]] &= [[∀α.|iN|]] \\
%     [[|∃α⁻.iP|]] &= [[∃α.|iP|]] \\
%   \end{aligned}
%   \end{equation*}
%   \caption{Type depolarization}
%   \label{fig:depolarization}
% \end{figure}

% The translation from \systemf to \fexists can be done in two canonical ways
% depending on the desired polarity. The polarity will also determine the 
% execution strategy \ilyam{how?}.
% Moreover, the translation procedure depends on the \emph{polarity} of the
% free type variables. Thus, the translation functions 
% $[[-| fT |-^Γ]]$ and $[[+| fT |+^Γ]]$ are indexed by a context $[[Γ]]$, 
% containing either $[[α⁺]]$ or $[[α⁻]]$ for each variable $[[α]]$ free in $[[fT]]$.

% \begin{figure}[h]
%   \begin{equation*}
%   \begin{aligned}
%     [[-| a |-^Γ]] &= [[α⁻]]  \text{,~if $[[α⁻ ∊ Γ]]$}\\
%     [[-| a |-^Γ]] &= [[↑α⁺]] \text{,~if $[[α⁺ ∊ Γ]]$}\\
%     [[-| fA → fB |-^Γ]] &= [[ +|fA|+^Γ → -|fB|-^Γ  ]] \\
%     [[-| ∀α.fT |-^Γ]] &= [[ ∀α⁺.-|fT|-^Γ,α⁺ ]] \\
%     [[-| ∃α.fT |-^Γ]] &= [[ ↑ ∃α⁻.+|fT|+^Γ,α⁻ ]] \\
%   \end{aligned}
%   \qquad
%   \begin{aligned}
%     [[+| a |+^Γ]] &= [[α⁺]]  \text{,~if $[[α⁺ ∊ Γ]]$}\\
%     [[+| a |+^Γ]] &= [[↓α⁻]] \text{,~if $[[α⁻ ∊ Γ]]$}\\
%     [[+| fA → fB |+^Γ]] &= [[ ↓ +|fA|+^Γ → -|fB|-^Γ  ]] \\
%     [[+| ∀α.fT |+^Γ]] &= [[ ↓∀α⁺.-|fT|-^Γ,α⁺ ]] \\
%     [[+| ∃α.fT |+^Γ]] &= [[ ∃α⁻.+|fT|+^Γ,α⁻ ]] \\
%   \end{aligned}
%   \end{equation*}
%   \caption{Type polarization}
%   \label{fig:polarization}
% \end{figure}


