\label{sec:extensions}

In this section, we discuss several extensions to the system and the algorithm.
Some of them can be incorporated into the system immediately, while others
are beyond the scope of this work, and thus are left for future research.
% In particular, \emph{Explicit Type Application} 

\subsection{Explicit Type Application}
\label{sec:explicit-type-application}

In our system, all type applications are inferred implicitly: the algorithm
automatically instantiates the variables abstracted by $\forall$. 
The implicit type application can be added to the declarative system by the following rule:
$$\ottdruleDTTypeAppLabeled{}$$

However, this rule alone would cause ambiguity.
The declarative system does not fix the order of the quantifiers, 
which means that $[[∀α⁺.∀β⁺.iN]]$ and $[[∀β⁺.∀α⁺.iN]]$ can be inferred 
as a type of $[[c]]$ interchangeably. But then explicit instantiation
$([[ c[iP] ]])$ would be ambiguous, as it is unclear whether $[[α⁺]]$ or
$[[β⁺]]$ should be instantiated with $[[iP]]$.

\paragraph{Solution 1: Declarative Normalization}
One way to resolve this ambiguity is to fix the order of quantifiers.  
The algorithm already performs the ordering of the quantifiers in the normalization procedure.
This way, we could require the inferred type to be normalized
to specify the order of the quantifiers:
$$\ottdruleDTTypeAppOrderedLabeled{}$$

The drawback of this approach is that it 
would cause the `leakage' of the internal algorithmic 
concept of type normalization into the `surface' declarative 
system. 

\paragraph{Solution 2: Elementary Type Inference}
An alternative approach to provide explicit type application
 was proposed by \cite{zhao22:elementary}.
In this work, the subtyping relation is restricted 
in such a way that 
$[[∀α⁺.∀β⁺.iN]]$ and $[[∀β⁺.∀α⁺.iN]]$ are \emph{not} mutual subtypes 
(as long as $[[α⁺ ∊ fv(iN)]]$ and $[[β⁺ ∊ fv(iN)]]$).
It implies that the order of the quantifiers of the inferred type is unique,
and thus, the explicit type application is unambiguous.

These restrictions can be incorporated into our system by
replacing the polymorphic subtyping rules
\ruleref{\ottdruleDOneForallLabel} and \ruleref{\ottdruleDOneExistsLabel}
with the following stronger versions:
% \vspace{-\baselineskip}
% \begin{multicols}{2}
% $$ \ottdruleDOneEForallR{} $$\\
% $$ \ottdruleDOneEForallL{} $$
% \end{multicols}

% \begin{multicols}{2}
% $$ \ottdruleDOneEExistsR{} $$\\
% $$ \ottdruleDOneEExistsL{} $$
% \end{multicols}
% \vspace{\baselineskip}

% \vspace{-\baselineskip}

\begin{minipage}{0.5\textwidth}
$$ \ottdruleDOneEForallLR{} $$
\end{minipage}%
\begin{minipage}{0.5\textwidth}
$$ \ottdruleDOneEExistsLR{} $$
\end{minipage}
\vskip 0.5em

According to these rules, if two polymorphic ($[[∀]]$ or $[[∃]]$) types are
subtypes of each other, they must have the same top-level quantifiers. Moreover,
the equivalence on types (mutual subtyping) degenerates to \emph{equality} up to
alpha-conversion. 

To accommodate these changes in the \emph{algorithm}, 
it suffices to 
    (i) replace the normalization procedure with identity: $[[nf(iN)]] \defeq [[iN]]$, $[[nf(iP)]] \defeq [[iP]]$,
        since the new equivalence classes consist of singletons;
    (ii) modify the least upper bound polymorphic rule \ruleref{\ottdruleLUBExistsLabel}
        so that it requires the quantifiers to be equal (and performs alpha-conversion if necessary):
        $$\ottdruleLUBEExists{}$$ 
    (iii) replace the subtyping polymorphic rule \ruleref{\ottdruleAForallLabel} 
    by the following rule:
        $$\ottdruleAForallLR{}$$
    and
    (iv) update the existential rule \ruleref{\ottdruleAExistsLabel} symmetrically.

After these changes, the rule \ruleref{\ottdruleDTTypeAppLabel} and its algorithmic counterpart
can be used to infer the the type of $[[ c[iP] ]]$.

The elementary type inference restricts the expressiveness of the subtyping perhaps too much.
As mentioned, it forbids the quantifier reordering; besides, 
as soon as the right-hand side of the subtyping relation is
polymorphic, it restricts the instantiation of the left-hand side quantifiers, 
which \emph{disallows}, for example, $[[· ⊢ ∀α⁺.↑α⁺ ≤ ∀α⁺.↑↓↑α⁺]]$.
On the other hand, the elementary subtyping system
can be smoothly extended with bounded quantification, which we discuss later.

\paragraph{Solution 3: Labeled Quantifiers}

A compromise solution that resolves the ambiguity of 
explicit the instantiation without fixing the order of
quantifiers is using \emph{labeled} quantifiers.
Let us discuss how to introduce them to the \emph{negative} part of the system,
since the positive subsystem is symmetric. 


Each type abstraction $[[Λl▷α⁺.c]]$ must be annotated with a label $[[l]]$.
This label propagates to the inferred polymorphic type. This way, each
polymorphic quantifier $[[ ∀ (li ▷* αi⁺)^I . iN ]]$ is annotated with a label
$[[li]]$ whose index is taken from the \emph{list} of labels $[[I]]$ associated
with the group of quantifiers. To instantiate a quantifying variable, one refers
to it by its label: $[[ c[lj ▷ iP] ]]$, which is expressed by the following
typing rules:

\begin{minipage}{0.4\textwidth}
$$\ottdruleDTTLamLbLabeled{}$$
\end{minipage}%
\begin{minipage}{0.6\textwidth}
$$\ottdruleDTTypeAppLbLabeled{}$$
\end{minipage}
\vskip 0.5em


The subtyping rule allows the quantifiers to have an arbitrary order. 
However, similarly to the elementary subtyping, 
each of the right-hand side quantifiers must have 
a matching left-hand side quantifier with the same label. These
matching quantifiers synchronously removed
(in other words, each variable is abstractly instantiated to itself), 
and the remaining quantifiers are instantiated as usual by
a substitution $[[σ]]$.
$$ \ottdruleDOneLblForallLRLabeled{} $$

The equivalence (mutual subtyping) in this system 
allows the quantifiers within the same group to be reordered
together with their labels. For instance,
$[[∀l▷α⁺.∀m▷β⁺.iN]]$ and $[[∀m▷β⁺.∀l▷α⁺.iN]]$ are subtypes of each other.
However, the right-hand side quantifiers are removed synchronously with 
the matching left-hand side quantifiers, which means that
$[[· ⊢ ∀l▷α⁺.↑α⁺ ≤ ∀l▷α⁺.↑↓↑α⁺]]$ is still not allowed.

\subsection{Weakening of the Subtyping Invariant}
\label{sec:weakening-invariant}

In order to make the subtyping relation decidable,
we made the subtyping of shifts \emph{invariant}, which manifests
in the following rules:

\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDOneShiftU{} $$
\end{minipage}%
\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDOneShiftD{} $$
\end{minipage}
\vskip 0.5em

To make the system more expressive, we can relax these rules. 
Although making both rules covariant would make the system undecidable,
it is possible to make the up-shift subtyping covariant while keeping the down-shift
invariant: 
$$ \ottdruleDOneShiftURlxLabeled{} $$\\
However, this change requires an update to the algorithm.
As one can expect,  
the corresponding algorithmic rule \ruleref{\ottdruleAShiftULabel}
must be changed accordingly:
$$ \ottdruleAShiftURlxLabeled{} $$
Also, notice that now the algorithmic variables can occur on \emph{both}
sides of the positive subtyping relation, and thus, a more sophisticated constraint 
solver is needed. To see what kind of constraints will be generated,
let us keep the other algorithmic rules unchanged for a moment
and make several observations.

First, notice that the negative quantification variables still only occur at
\emph{invariant} positions: the negative variables are generated from the existential
quantifiers $[[∃α⁻.iP]]$, and the switch from a positive to a negative type in the syntax path
to $[[α⁻]]$ in $[[iP]]$ is `guarded' by \emph{invariant} down-shift. It means
that in the algorithm, the negative constraint entries can only be equivalence
entries ($[[nua :≈ iN]]$) but not subtyping entries. 

Second, notice that the positive subtyping is still not dependent on the negative
subtyping. It means, that any leaf-to-root path in the inference tree is monotonous:
in the first phase, the negative subtyping rules are applied, and in the second phase, 
only the positive ones.

The invariant that only the left-hand side of the judgment is algorithmic is not
preserved. However, the only rule violating this invariant is
\ruleref{\ottdruleDOneShiftURlxLabel}, and it is placed at the interface between
negative subtyping and positive subtyping. It means that the \emph{negative}
algorithmic variables (produced by $[[∃]]$ in the positive phase of the
inference path) still only occur on the left-hand side of the judgment, and the
positive algorithmic variables (produced by $[[∀]]$ in the first phase) can
occur either on the left-hand side or on the right-hand side (if the switch from
the negative to the positive phase is made by \ruleref{\ottdruleDOneShiftURlxLabel})
but not both.
This way, the produced entries will be of the following form:
\begin{itemize*}
    \item[(i)] $[[pua :≈ uP]]$, 
    \item[(ii)] $[[nua :≈ uN]]$, 
    \item[(iii)] $[[pua :≥ iP]]$, and
    \item[(iv)] $[[pua :≤ uP]]$ where $[[uP]]$ does not contain positive unification variables.
\end{itemize*}

We do not present the details of the constraint resolution procedure or how it
is integrated into the subtyping algorithm, leaving it for future work. However,
we believe that the system consisting of the mentioned kinds of constraints is solvable
by the following reasons.
\begin{enumerate*}
    \item[(i)] The equivalence entries $[[pua :≈ uP]]$ and $[[nua :≈ uN]]$ are resolved by standard first-order pattern unification techniques.
    \item[(ii)] The resolution of supertyping entries ($[[pua :≥ iP]]$) is discussed in the original algorithm (\cref{sec:constraint-merge}).
    \item[(iii)] The new kind of entries $[[pua :≤ uP]]$ can be
        reduced by case analysis. If $[[uP]]$ is a variable $[[β⁺]]$
        or a shifted computation $[[↓uN]]$ then 
        $[[pua :≤ uP]]$ is equivalent to $[[pua :≈ uP]]$;
        otherwise, $[[pua :≤ ∃nas.↓uN]]$ is equivalently replaced by $[[pua :≈ [nuas/nas]↓uN]]$
        for freshly created $[[nuas]]$.
\end{enumerate*}

This way, the algorithm can be extended to support the \emph{covariant} up-shift
subtyping. This, for example, enriches the relation with such subtypes as $[[· ⊢
∀α⁺.α⁺→↑α⁺ ≤ ↓↑Int → ↑∃β⁻.↓β⁻]]$, which does not hold in the original system.
Moreover, this extension also increases the expressiveness of the \emph{type
inference}. Namely, when inferring a type of an annotated let binding 
$[[let x:iP = v(args); c]]$, we require $[[↑iP]]$ to be a supertype of 
$[[↑iQ]]$---the resulting type of the application $[[v]]([[args]])$. 
Now, it is equivalent to the requirement that $[[iP]]$ is a supertype of $[[iQ]]$
(without the up-shift), which is more permissive.

In addition, the enhancement of the unification algorithm described above
makes possible another improvement to the system---bounded quantification.

\subsection{Bounded Quantification}

After the weakening of subtyping invariants, 
it is possible to smoothly extend the \emph{elementary}
version of the system with bounded quantification.
In particular, we can add upper bounds to polymorphic $[[∀]]$-quantifiers:
$[[∀(pa ≤* iP). iN]]$. 

The declarative subtyping rules for bounded quantification are as expected:
the instantiation of quantified variables must satisfy the corresponding bounds
($[[Γ, pas ⊢ iQi ≥ [σ]βi⁺]]$ holds for each $i$);
and the right-hand side quantifiers must be more restrictive than the matching left-hand side
quantifiers ($[[Γ ⊢ iPi ≥ iP'i]]$ for each $i$):
$$\ottdruleDOneEForallLRUbLabeled{}$$

The corresponding algorithmic rule, as before,
replaces the polymorphic variables $[[β1]]\dots$ with fresh 
algorithmic variables $[[β1̂⁺]]\dots$, and merges the generated
constraints with the constraints given in the bounds
$[[βî⁺ :≤ uQi]]$:
$$\ottdruleAEForallLRUbLabeled{}$$

Notice that the algorithmic rule \ruleref{\ottdruleAEForallLRUbLabel}
requires the bounding types $[[iPs]]$ and $[[iQs]]$ to be \emph{declarative}.
Because of that, the generated constraints have shape $[[βî⁺ :≤ iQi]]$,
\ie the bounding types do not contain algorithmic variables.
This kind of constraints is covered by the resolution procedure described in
\cref{sec:weakening-invariant}, and thus, \ruleref{\ottdruleAEForallLRUbLabel} fits 
into the algorithmic system without changes to the constraint solver.

However, in order for this rule to be complete, 
the declarative system must be restricted as well.
To guarantee that no algorithmic variable is introduced in the bounding types,
we need to forbid the quantifying variables to occur in the bounding types in the declarative system.
For that purpose, we must include this requirement in the type well-formedness
(here $[[bv iN]]$ denotes the set of variables freely occurring 
in the quantifiers of $[[iN]]$ at any depth):
$$\ottdruleWFTForallUbLabeled{}$$

For brevity, we do not discuss in detail the combination of bounded and
unbounded quantification in one system. However, this update is straightforward:
the unbounded quantifiers are treated as the weakest bound, which is trivially
satisfied. Analogously, it is possible to extend the system with \emph{lower}
bound $[[∀]]$-quantifiers: $[[∀(pa ≥* iP). iN]]$. 
Then the generated constraints will change to $[[βî⁺ :≥ iQi]]$, which 
is also covered by the resolution procedure.
However, we do not consider bounded \emph{existential} quantification,
because in this case, the constraint resolution would require us to 
find the \emph{greatest lower bound} of two negative types, which is not
well-defined (see \cref{sec:constraint-merge}).

\subsection{Bidirectionalization}

% \subsubsection{Declarative System}
% \ottdefnDTNSynth{}
% \ottdefnDTNCheck{}
% \ottdefnDTNCheckSynth{}
% \ottdefnDTPSynth{}
% \ottdefnDTPCheck{}
% \ottdefnDTPCheckSynth{}
% \ottdefnDTSpinInfBidir{}

% \subsubsection{Algorithmic System}
% \ottdefnATNSynth{}
% \ottdefnATNCheck{}
% \ottdefnATNCheckSynth{}
% \ottdefnATPSynth{}
% \ottdefnATPCheck{}
% \ottdefnATPCheckSynth{}
% \ottdefnATSpinInfBidir{}




The algorithm we provide requires that all lambda functions are annotated. 
This restriction significantly simplifies the type inference by making the 
terms uniquely define their types. However, it leads to certain redundancies
in typing, in particular, the type of a lambda expression cannot be inferred 
from the context it is used in: $[[((λ x . return x) : (Int → ↑Int))]]$
is not allowed.

The well-known way to incorporate this expressiveness into the system
is to make the typing bidirectional \cite{dunfield2020:bidirectional}.
The idea is to split the typing judgment into two kinds:
\begin{enumerate}
    \item[(i)] \emph{Synthesis} 
        judgments are used when the type of a term can be \emph{inferred}
        based exclusively on the term itself. 
        Syntactically, we denote synthesizing judgments
        as $[[Γ ; Φ ⊢ c ⇒ iN]]$.
    \item[(ii)] \emph{Checking} judgments 
        assume that the type of a term is \emph{given}
        from the context, and 
        it is required to \emph{check} that the given
        type can be assigned to the term.
        In checking judgments $[[Γ ; Φ ⊢ c ⇐ iN]]$, 
        the type $[[iN]]$ is considered as an \emph{input}.
\end{enumerate}

To bidirectionalize the system, each typing rule 
must be oriented either to synthesis or to checking (or both).
In particular, the \emph{annotated} lambda-abstractions are
synthesizing, and the \emph{unannotated} ones are checking.

\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDTtLamSynLabeled{} $$
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDTtLamChkLabeled{} $$
\end{minipage}
\vskip 0.5em


As common for bidirectional systems with subtyping, 
we would also need to introduce the \emph{subsumption} rules.
They allow us to `forget' the information about the type
by switching to the synthesis mode, as long as the synthesized
type is more polymorphic than the checked one:

\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDTNSubLabeled{} $$
\end{minipage}
\hfill
\begin{minipage}{0.5\textwidth}
    $$ \ottdruleDTPSubLabeled{} $$
\end{minipage}
\vskip 0.5em

Most of the original rules will have two bidirectional counterparts,
one for each mode. The premises of the rules are oriented with respect to the conclusion.
For instance, we need both checking and inferring versions for $[[return v]]$: 
    $$ \ottdruleDTReturnChkSynLabeled{} $$
For some rules, however, it only makes sense to have one mode.
As mentioned above, the unannotated lambda-abstraction is always checking. 
On the other hand, an \emph{annotated} lambda, type-level lambda abstraction, 
or a variable inference is always synthesizing, since
the required type information is already given in the term:

\begin{minipage} {0.5\textwidth}
    $$ \ottdruleDTTLamSynLabeled{} $$
\end{minipage}
\hfill
\begin{minipage} {0.5\textwidth}
    $$ \ottdruleDTVarSynLabeled{} $$
\end{minipage}
\vskip 0.5em

Finally, let us discuss the application inference part of the declarative system. 
Rules \ruleref{\ottdruleDTEmptyAppLabel} and \ruleref{\ottdruleDTForallAppLabel} are 
unchanged: they simply do not have typing premises to be oriented.
However, the arrow application rule \ruleref{\ottdruleDTArrowAppLabel}
infers the result of the application of an arrow $[[iQ → iN]]$ 
to a list of arguments $[[v , args]]$, 
and it must make sure that the first argument $[[v]]$ is typeable with the expected $[[iQ]]$.
As we will discuss further, simply checking $[[Γ; Φ ⊢ v ⇐ iQ]]$ turns out to be too 
powerful and potentially leads to undecidability. 
Instead, this check is approximated by the combination of $[[Γ; Φ ⊢ v ⇒ iP]]$
and $[[Γ ⊢ iQ ≥ iP]]$.

\paragraph{The Algorithm}

    The algorithmic system is bidirectionalized in a similar way. 
    Each typing premise and the conclusion of the rule is oriented
    to either `checking` ($[[⇐]]$) or `synthesizing` ($[[⇒]]$) mode,
    with respect to the declarative system. 
 
    For brevity, we omit the details of the bidirectional algorithm.
    However, let us discuss one especially important rule---arrow application inference. 
    An intuitive way to bidirectionalize this rule is the following:
    $$ \ottdruleATArrowAppBidirLabeled{} $$\\
    % \paragraph{Reaching Undecidability}
    However, this rule is too allowing. 
    The judgement $[[Γ ; Φ ⊨ v ⇐ uQ ⫤ SC1]]$
    requires us to check a term against an \emph{algorithmic} 
    type $[[uQ]]$. Further, through the
    lambda function checking \ruleref{\ottdruleDTtLamChkLabel}
    the algorithmic types infiltrate the type context
    and then through variable inference and subsumption, 
    \emph{both} sides of subtyping. 
    This way, \ruleref{\ottdruleATArrowAppBidirLabel}
    compromises the important invariant
    of the subtyping algorithm: 
    now the same algorithmic variable can occur on \emph{both}
     sides of the subtyping relation.

    We believe that the relaxation of this invariant brings the 
    constraint resolution too close to the second-order pattern 
    unification, which is undecidable \cite{goldfarb81:undecidability}.
    In particular, the constraint $[[(α̂⁺ :≥ ↓↑α̂⁺)]]$ is solvable with 
    $[[α̂⁺]] = [[∃β⁻.↓β⁻]]$, 
    since by \ruleref{\ottdruleDOneExistsLabel}, 
    the existential $[[β⁻]]$ can be impredicatively instantiated to $[[↑∃β⁻.↓β⁻]]$. 

    The constraints such as $[[(α̂⁺ :≥ ↓↑α̂⁺)]]$ are not merely hypothetical. 
    It occurs, for example, when we infer the type of the following application:
    $$[[· ; · ⊢ ∀α⁺ . ↓(α⁺ → ↑Int) → ↓↑α⁺ → ↑Int ● {λx.λy.let y' = x(y); return y'} ⇒> ↑Int]]$$
    For $[[x]]$ to be applicable to $[[y]]$,
    the type of $[[y]]$---$[[↓↑α⁺]]$ must be a subtype of
    $[[α⁺]]$---the type expected by $[[x]]$. This way, 
    this inference is possible if and only if
    $[[(α̂⁺ :≥ ↓↑α̂⁺)]]$ is solvable.
    Using a similar scheme, we can construct different examples
    whose resolution significantly relies on second-order pattern unification.
    Thus, we leave the resolution of this type of constraints beyond the scope of this work.

    % \paragraph{Restricting Inference}
    Instead, we strengthen
    \ruleref{\ottdruleATArrowAppBidirLabel}
    in such a way that it never checks a term against an algorithmic type.
    Instead, type checking $[[v]]$ against $[[uQ]]$ is replaced by 
    a more restrictive premise---checking that $[[v]]$ \emph{synthesizes a subtype} of $[[uQ]]$:
    $$ \ottdruleATArrowAppBidirSLabeled{} $$\\

    As one can expect, the declarative rule is also changed accordingly.
    In terms of practicality, this change disallows
    implicit checking against a \emph{polymorphic} type:
    $[[·;· ⊢ λx.return x ⇐ ∀α⁺.α⁺ → ↑α⁺]]$ is not allowed, because
    it would require adding algorithmic $[[x:α̂⁺]]$ to the context.
    However, once the instantiation is made explicit or the lambda is explicitly 
    polymorphic, the checking is allowed:
     $[[·;· ⊢ λx.return x ⇐ Int → ↑Int]]$ and 
     $[[·;· ⊢ Λα⁺.λx:α⁺.return x ⇐ ∀α⁺.α⁺ → ↑α⁺]]$ are both valid.
