\PassOptionsToPackage{prologue,dvipsnames}{xcolor}

% \UseRawInputEncoding
% vim: ft=tex

% \documentclass[acmsmall,natbib=false]{article}
% \usepackage[a4paper, total={8in, 10in}]{geometry}

\documentclass[acmsmall,natbib=false,review,anonymous]{acmart}
\input{../prelude.tex}

\newcommand{\ottDir}{../ott/_gen}
\newcommand{\genDir}{_gen}
\input{\ottDir/defs.tex}
\input{\ottDir/renew-ott.tex}

\usepackage{../bibliography}
% \usepackage{amssymb}

\usepackage[matha]{mathabx}

% https://tex.stackexchange.com/questions/85033/colored-symbols/85035#85035
% \newcommand*{\mathcolor}{}
% \def\mathcolor#1#{ \mathcoloraux{#1} }
% \newcommand*{\mathcoloraux}[3]{%
%   \protect\leavevmode
%   \begingroup
%   \color#1{#2}#3%
%   \endgroup
% }

\begin{document}

\title{The Proofs}

\maketitle

\tableofcontents

\newpage

\section{Declarative Type Systems}

\subsection{Grammar}
We assume that there is an infinite set of positive and 
negative \emph{type} variables. Positive type variables are denoted as 
$[[α⁺]]$, $[[β⁺]]$, $[[γ⁺]]$, etc.
Negative type variables are denoted as $[[α⁻]]$, $[[β⁻]]$, $[[γ⁻]]$, etc.
We assume there is an infinite set of \emph{term} variables,
which are denoted as $[[x]]$, $[[y]]$, $[[z]]$, etc.
A list of objects (variables, types or terms) is denoted by
an overline arrow. For instance, $[[pas]]$ is a list of positive type variables, 
$[[nbs]]$ is a list of negative type variables, 
$[[args]]$ is a list of values, which are arguments of a function.
$[[fv(iP)]]$ and $[[fv(iN)]]$ denote the set of free variables 
in a type $[[iP]]$ and $[[iN]]$, respectively.

\bigskip

% \ottgrammartabular{
%   \ottiP\ottinterrule
%   \ottiN\ottinterrule
% }

\begin{definition}[Declarative Types]
  \hfill
  \begin{multicols}{2}
    \ottgrammartabular{
      \ottiN\ottinterrule
    }

    \ottgrammartabular{
      \ottiP\ottinterrule
    }
    \columnbreak
  \end{multicols}
\end{definition}

\subsection{Equalities}
For simplicity, we assume alpha-equivalent terms equal.
This way, we assume that substitutions do not capture bound variables.
Besides, we equate
$[[∀pas.∀pbs.iN]]$ with $[[∀pas,pbs.iN]]$, 
as well as $[[∃nas.∃nbs.iP]]$ with $[[∃nas,nbs.iP]]$,
and lift these equations transitively and congruently 
to the whole system.

\subsection{Contexts and Well-formedness}

\begin{definition}[Declarative Type Context]
  \hfill \\
  Declarative type context $[[Γ]]$ is represented by a set of 
  type variables. The concatenation $[[Γ1, Γ2]]$ means the 
  union of two contexts $[[Γ1 ∪ Γ2]]$.
\end{definition}

$[[Γ ⊢ iP]]$ and $[[Γ ⊢ iN]]$ denote that the type is well-formed in the context $[[Γ]]$,
which, in fact, means that each free type variable of the type is contained in $[[Γ]]$
(it will be shown later in \cref{lemma:wf-soundness,lemma:wf-ctxt-equiv}).

Notice that checking the well-formedness of a type
is an \emph{algorithmic} procedure, in which 
both the context and the type are considered inputs.
In other words, it is syntax-directed and mode-correct 
(according to \cite{dunfieldBidirectionalTyping2020}), 
which means that 

\begin{algorithm}[Type Well-formedness]
  \label{alg:wf}
  \hfill
  
  \begin{multicols}{2}
  \ottdefnWFTNiWF{}
  \columnbreak

  \ottdefnWFTPiWF{}
  \end{multicols}

\end{algorithm}


\subsection{Substitutions}

\begin{definition}[Substitution]
  Substitutions (denoted as $[[σ]]$) 
  are represented by total functions form variables to types, preserving the polarity. 
\end{definition}

\begin{algorithm}[Substitution Application]
  Substitution application is denoted as $[[ [σ]iP ]]$ and $[[ [σ]iN ]]$.
  It is defined naturally as follows:
    \begin{multicols}{2}
      \begin{itemize}
        \item[] $[[ [σ]α⁺ ]] = [[σ]] ([[α⁺]])$
        \item[] $[[ [σ]α⁻ ]] = [[σ]] ([[α⁻]])$
        \item[] $[[ [σ]↓iN ]] = [[↓[σ]iN]]$
        \item[] $[[ [σ]↑iP ]] = [[↑[σ]iP]]$
        \item[] $[[ [σ](iP → iN) ]] = [[ [σ]iP → [σ]iN ]]$
        \item[] $[[ [σ]∃nas.iQ ]] = [[∃nas.[σ]iQ]]$ 
        \item[] $[[ [σ]∀pas.iN ]] = [[∀pas.[σ]iN]]$ (assuming the variable capture never happens)
      \end{itemize}
    \end{multicols}
\end{algorithm}

\begin{definition}[Substitution Signature]
  The signature $[[Γ' ⊢ σ : Γ]]$ means that
  \begin{enumerate}
    \item for any $[[α± ∊ Γ]], [[ Γ' ⊢ [σ]α± ]]$; and
    \item for any $[[α± ∉ Γ']], [[ [σ]α± = α± ]]$.
  \end{enumerate}
\end{definition}

A substitution can be restricted to a set of variables. 
The restricted substitution is define as expected. 
\begin{definition}[Subsitution Restriction]
  The specification $[[σ  | varset]]$ is defined as
  a function such that 
  \begin{enumerate}
    \item $[[σ|varset]]([[α± ]]) = [[σ]]([[α± ]])$, if $[[α± ]] \in [[varset]]$; and
    \item $[[σ|varset]]([[α± ]]) = [[α± ]]$, if $[[α± ]] \notin [[varset]]$.
  \end{enumerate}
\end{definition}

Two substitutions can be composed in two ways:
$[[σ2 ○ σ1]]$ corresponds to a consecutive application of $[[σ1]]$ and $[[σ2]]$,
while $[[σ2 <=< σ1]]$
depends on a signature of $[[σ1]]$ and modifies $[[σ1]]$ by applying
$[[σ2]]$ to its results on the domain.
\begin{definition}[Substitution Composition]
  $[[σ2 ○ σ1]]$ is defined as a function such that
  $[[σ2 ○ σ1]]([[α± ]]) = [[σ2]]([[σ1]]([[α± ]]))$.
\end{definition}

\begin{definition}[Monadic Substitution Composition]
  Suppose that $[[Γ' ⊢ σ1 : Γ]]$.
  Then we define $[[σ2 <=< σ1]]$ as $[[(σ2 ○ σ1)|Γ]]$.
\end{definition}
Notice that the result of $[[σ2 <=< σ1]]$ depends on the 
specification of $[[σ1]]$, which is not unique. 
However, we assume that the used specification clear from the 
context of the proof. 

\begin{definition}[Equivalent Substitutions]
  The substitution equivalence judgement $[[Γ' ⊢ σ1 ≈ σ2 : Γ]]$ 
  indicates that on the domain $[[Γ]]$, 
  the result of $[[σ1]]$ and $[[σ2]]$ are equivalent in context $[[Γ']]$.
  Formally, for any $[[α± ∊ Γ]], [[ Γ' ⊢ [σ1]α± ≈ [σ2]α± ]]$.
\end{definition}

Sometimes it is convenient to construct substitution 
explicitly mapping each variable from a list (or a set)
to a type. Such substitutions are denoted as $[[iPs / pas]]$
and $[[iNs / nas]]$, where $[[iPs]]$ and $[[iNs]]$ are lists of 
the corresponding types.
\begin{definition}[Explicit Substitution]
  \hfill
  \begin{itemize}
    \item [$-$]
      Suppose that $[[nas]]$ is a list of negative type variables,
      and $[[iNs]]$ is a list of negative types of the same length.
      Then $[[iNs / nas]]$ denotes a substitution such that 
      \begin{enumerate}
        \item for $[[αi⁺ ∊ {nas}]]$, $[[ [iNs / nas] αi⁺]] = [[iNi]]$;
        \item for $[[β⁺ ∉ {nas}]]$, $[[ [iNs / nas] β⁺]] = [[β⁺]]$.
      \end{enumerate}
    \item [$+$]
      Positive explicit substitution $[[iPs / pas]]$
      is defined symmetrically.
  \end{itemize}
\end{definition}


\subsection{Declarative Subtyping}
Subtyping is one of the key mechanism of our system. 
It realizes the polymorphism: abstract $[[∀]]$ and 
$[[∃]]$ types can be used where concrete types are expected,
exactly because the subtyping relation between them.

\begin{definition} 
  \label{def:subDOne}
  \hfill
  
  \begin{multicols}{2}
    \ottdefnDOneNsub{}

    \ottdefnDOnePsup{}
  \end{multicols}
  \hfill

  \begin{multicols}{2}
    \ottdefnDOneNeq{}

    \ottdefnDOnePeq{}
  \end{multicols}
\end{definition}

The following observations about the declarative subtyping are worth noting:
\begin{itemize}
  \item \ruleref{\ottdruleDOneNVarLabel} and \ruleref{\ottdruleDOnePVarLabel}
    make the subtyping reflexive on variables (and further, on any type).
  \item \ruleref{\ottdruleDOneArrowLabel} is standard: the arrow is covariant on the
    resulting type and contravariant on the argument type.
  \item \ruleref{\ottdruleDOneShiftDLabel}  and \ruleref{\ottdruleDOneShiftULabel} are non-standard:
    the subtyping is \emph{invariant} for shifts. 
    This way, the subtyping of shifted types in one direction implies the subtyping
    in the opposite direction.
    Although this rule restricts the
    subtyping relation, it makes the system decidable.
  \item \ruleref{\ottdruleDOneForallLabel} and \ruleref{\ottdruleDOneExistsLabel} are the only
    non-algorithmic rules: the substitution for the quantified variable is
    not specified, those, these rules `drive' the subtyping relation.
\end{itemize}

In the next section, we present the sound and complete algorithm
checking whether one type is a subtype of another according to \cref{def:subDOne}. 

\section{Algorithmic Type System}

\subsection{Grammar}

In the algorithmic system, we extend the grammar of types
by adding positive and negative \emph{algorithmic variables}
($[[α̂⁺]]$, $[[β̂⁺]]$, $[[γ̂⁺]]$, etc. and $[[α̂⁻]]$, $[[β̂⁻]]$, $[[γ̂⁻]]$, etc.).
They represent the unknown types, which will be inferred by the algorithm.
This way, we add two base cases to the grammar of 
positive and negative types and use highlight to denote that the type
can potentially contain algorithmic variables.

\begin{definition}[Algorithmic Types]
  \label{def:algo-types}
  \hfill\\
  \begin{multicols}{2}
    \ottgrammartabular{
      \ottuN\ottinterrule
    }

    \ottgrammartabular{
      \ottuP\ottinterrule
    }
    \columnbreak
  \end{multicols}
\end{definition}

\subsection{Fresh Variable Selection}
\label{sec:fresh-selection}
Both the subtyping and the type inference algorithm
rely on the ability to select fresh, unused variables.
For a set of variables $[[varset]]$, it is indicated as 
$[[varset are fresh]]$ in the inference rules.
We assume that the selection subroutine always succeeds and is 
deterministic. In other words, whenever it is called in 
an algorithmic inference rule, it returns the same result, 
uniquely determined by the input of this rule.

\subsection{Variable Algorithmization}
\label{sec:variable-algorithmization}

In several places of our algorithm, in particular, during
algorithmic subtyping,
we turn a declarative type into an algorithmic one
via replacing certain type variables with fresh algorithmic variables.
We call this procedure \emph{variable algorithmization}, and define it as follows.

\begin{definition}[Variable Algorithmization]
  Suppose that $[[nas]]$ is a list of negative type variables
  and $[[nuas]]$ is a list of negative algorithmic variables of the same length. 
  Then $[[ nuas/nas ]]$ is a substitution-like procedure replacing each $[[αi⁻ ∊ {nas}]]$
  in a type for $[[αî⁻ ∊ {nuas}]]$.
\end{definition}

Conversely, we have the opposite procedure turning algorithmic type variables
into declarative type variables via \emph{dealgorithmization}.

\begin{definition}[Variable Dealgorithmization]
  Suppose that $[[nuas]]$ is a list of negative algorithmic variables
  and $[[nas]]$ is a list of negative type variables of the same length. 
  Then $[[ nas/nuas ]]$ is a substitution-like procedure replacing each
  $[[αî⁻ ∊ {nuas}]]$ in a type for $[[αi⁻ ∊ {nas}]]$.
\end{definition}


\subsection{Contexts and Well-formedness}

\begin{definition}[Algorithmic Type Context $[[Ξ]]$]
  \hfill \\
  Algorithmic type context $[[Ξ]]$ is represented by a set of 
  \emph{algorithmic} type variables ($[[α̂⁺]]$, $[[α̂⁻]]$, $[[β̂⁺]]$, \dots).
  The concatenation $[[Ξ1, Ξ2]]$ means the union of two contexts $[[Ξ1 ∪ Ξ2]]$.
\end{definition}

$[[Γ ; Ξ ⊢ uP]]$ and $[[Γ ; Ξ ⊢ uN]]$ are used to denote
that the algorithmic type is well-formed in the contexts
$[[Γ]]$ and $[[Ξ]]$, which means that each algorithmic variable
of the type is contained in $[[Ξ]]$, and each free declarative type variable
of the type is contained in $[[Γ]]$.

\begin{algorithm}[Algorithmic Type Well-formedness]
  \hfill
  
  \begin{multicols}{2}
  \ottdefnWFATNauWF{}
  \columnbreak

  \ottdefnWFATPauWF{}
  \end{multicols}

\end{algorithm}


Algorithmic Type Context are used in the unification algorithm.
In the subtyping algorithm, 
the context needs to remember additional information.
In the subtyping context, each algorithmic variable is associated with a
context it must be instantiated in 
(i.e. the context in which the type replacing the variable must be well-formed).
This association is represented by \emph{algorithmic subtyping context} $[[Θ]]$.
\begin{definition}[Algorithmic Subtyping Context $[[Θ]]$]
  \hfill \\
  Algorithmic Subtyping Context $[[Θ]]$ is represented by a set of 
  entries of form $[[ α̂⁺[Γ] ]]$ and $[[ α̂⁻[Γ] ]]$,
  where $[[α̂⁺]]$ and $[[α̂⁻]]$ are algorithmic variables,
  and $[[Γ]]$ is a context in which they must be instantiated.
  We assume that no two entries associating the same variable
  appear in $[[Θ]]$.

  $[[dom(Θ)]]$ denotes the set of variables appearing in $[[Θ]]$:
  $[[dom(Θ)]] = \{ [[α̂±]] \mid [[α̂±[Γ] ]] \in [[Θ]] \}$.
  If $[[ α̂±[Γ] ]] \in [[Θ]]$, we denote $[[Γ]]$ as $[[Θ(α̂±)]]$.
\end{definition}


\subsection{Subsitutions}

Substitution that operates on algorithmic type variables is denoted as
$[[uσ]]$. It is defined as a total function from algorithmic 
type variables to \emph{declarative} types, preserving the polarity.

The signature $[[Θ ⊢ uσ : Ξ]]$ means that
$[[Ξ ⊆ dom(Θ)]]$ and 
$[[uσ]]$ maps each algorithmic variable 
from $[[Ξ]]$ to a type well-formed in $[[Θ(α̂±)]]$;
and for each variable not appearing in $[[dom(Θ)]]$, 
it acts as identity.

\begin{definition}[Signature of Algorithmic Substitution]
  \label{def:algo-subst-sig}
  \hfill
  \begin{itemize}
    \item $[[Θ ⊢ uσ : Ξ]]$ means that
      \begin{enumerate}
        \item for any $[[α̂± ∊ Ξ]]$,
          there exists $[[Γ]]$ such that $[[ α̂±[Γ] ∊ Θ ]]$
          and $[[ Γ ⊢ [uσ]α̂± ]]$; 
        \item for any $[[ α̂± ∉ Ξ]]$, $[[ [uσ]α̂± ]] =  [[ α̂± ]]$.
      \end{enumerate}
    \item $[[Γ ⊢ uσ : Ξ]]$ means that
      \begin{enumerate}
        \item for any $[[α̂± ∊ Ξ]]$, $[[ Γ ⊢ [uσ]α̂± ]]$; 
        \item for any $[[ α̂± ∉ Ξ]]$, $[[ [uσ]α̂± ]] =  [[ α̂± ]]$.
      \end{enumerate}
  \end{itemize}
\end{definition}

In the anti-unification algorithm, we use another kind of substitution.
In contrast to algorithmic substitution $[[uσ]]$,
it allows mapping algorithmic variables to
\emph{algorithmic} types.
Additionally, anti-unification substitution is restricted to the
\emph{negative} segment of the language.
Anti-unification substitution is denoted as $[[aus]]$ and $[[ausr]]$.a

The pair of contexts $[[Γ]]$ and $[[Ξ]]$,
in which the results of an anti-unification substitution 
are formed, is fixed for this substitution.
This way, $[[Γ; Ξ2 ⊢ aus : Ξ1]]$ means that $[[aus]]$ maps each negative algorithmic
variable appearing in $[[Ξ1]]$ to a term well-formed in $[[Γ]]$ and $[[Ξ2]]$.

\begin{definition}[Signature of Anti-unification substitution]
  $[[Γ; Ξ2 ⊢ aus : Ξ1]]$ means that
  \begin{enumerate}
    \item for any $[[ α̂⁻ ∊ Ξ1]]$, $[[ Γ; Ξ2 ⊢ [aus]α̂⁻ ]]$ and
    \item for any $[[ α̂⁻ ∉ Ξ1]]$, $[[ [aus]α̂⁻ = α̂⁻ ]]$.
  \end{enumerate}
\end{definition}

\subsection{Equivalence and Normalization}
\label{sec:equivalence-normalization}

The subtyping-induced equivalence (\cref{def:subDOne}) is non-trivial:
there are types that are subtypes of each other but not equal. 
For example, $[[∀α⁺,β⁺.α⁺ → ↑β⁺]]$ is a subtype and a supertype of $[[∀α⁺,β⁺.β⁺ → ↑α⁺]]$
and of, for example, $[[∀α⁺,β⁺.β⁺ → ↑∃γ⁻.α⁺]]$, 
although these types are not alpha-equivalent.
For the subtyping algorithm, it is crucial to be able to check whether
two types are equivalent, without checking mutual subtyping. 
For this purpose we define the normalization procedure, 
which allows us to uniformly choose the representative type of the equivalence class.
This way, the equivalence checking is reduced to normalization and equality checking. 

For clarification of the proofs and better understanding of the system, 
we introduce an intermediate relation---\emph{declarative equivalence}. 
As will be shown in \cref{lemma:equiv-soundness,lemma:equiv-completeness}, 
this relation is equivalent to the subtyping-induced equivalence, but does not 
depend on it. Although this relation is not defined algorithmically, 
it gives the intuition of what types our system considers equivalent.
Specifically, in addition to \emph{alpha-equivalence}, 
our system allows for \emph{reordering of adjacent quantifiers},
and \emph{introduction/elimination of unused quantifiers}.

The non-trivial rules of the declarative equivalence are
\ruleref{\ottdruleEOneForallLabel} and \ruleref{\ottdruleEOneExistsLabel}.
Intuitively, the variable bijection $[[μ]]$ reorders the quantifiers before
the recursive call on the body of the quantified type. 
It will be covered formally in \cref{sec:decl-equiv-lemmas}.

\begin{definition}[Declarative Type Equivalence]
  \hfill
  
  \begin{multicols}{2}
  \ottdefnEOneNeq{}
  \columnbreak\\
  \ottdefnEOnePeq{}
  \end{multicols}

\end{definition}

As the equivalence includes arbitrary reordering of quantified variables,
the normalization procedure is needed to choose the canonical order.
For this purpose, we introduce an auxiliary procedure---variable ordering. 
Intuitively, $[[ord varset in iN]]$ returns a list of variables from $[[varset]]$
in the order they appear in $[[iN]]$.

\begin{algorithm}[Variable Ordering]
  \label{alg:var-ordering}
  \hfill
  
  \ottdefnONVar{}
  \ottdefnOPVar{}

  Analogously, the variable can be ordered in 
  an \emph{algorithmic} type ($[[ord varset in uP]]$ and 
  $[[ord varset in uN]]$). In these cases, we treat the algorithmic variables
  as if they were declarative variables.

\end{algorithm}

Next, we use the variable ordering in the normalization procedure. 
Specifically, normalization recursively traverses the type, 
and for each quantified case reorders the quantified variables in a 
canonical order dictated by \cref{alg:var-ordering}, removing unused ones.

\begin{algorithm}[Type Normalization]
  \label{alg:type-nf}
  \hfill
  
  \begin{multicols}{2}
  \ottdefnNrmNNorm{}
  \columnbreak\\
  \ottdefnNrmPNorm{}
  \end{multicols}

  Analogously, we define the normalization of algorithmic types by adding base cases:

  \begin{multicols}{2}
  \ottdefnNrmuNNorm{}
  \columnbreak\\
  \ottdefnNrmuPNorm{}
  \end{multicols}

\end{algorithm}

\Cref{lemma:subt-equiv-algorithmization}
demonstrates that the equivalence of types is the same
as the equality of their normal forms.
\begin{theorempreview}[Correctness of Normalization]
  Assuming the types are well-formed in $[[Γ]]$, 
  \begin{itemize}
    \item [$-$] $[[Γ ⊢ iN ≈ iM]]$ if and only if $[[nf(iN) = nf(iM)]]$;
    \item [$+$] $[[Γ ⊢ iP ≈ iQ]]$ if and only if $[[nf(iP) = nf(iQ)]]$.
  \end{itemize}
\end{theorempreview}



\begin{algorithm}[Substitution Normalization]
  For a substitution $[[σ]]$, we define $[[nf(σ)]]$
  as a substitution that maps $[[α±]]$ into $[[nf([σ]α±)]]$.
\end{algorithm}

The rest of this chapter is devoted to the
central algorithm of the type system---the subtyping algorithm. 
\Cref{fig:subtyping-algo} shows the dependency graph of the subtyping algorithm.
The nodes represent the algorithmic procedures, and the edge $A \to B$ means that 
$A$ uses $B$ as a sub-procedure.



\begin{figure}[h]
  \centering
  \begin{tikzpicture}
    [>={Stealth[scale=2]},node distance=2.4cm,every node/.style={draw,rectangle},every text node part/.style={align=center}]


    % Define nodes
    \node[] (1) {Negative Subtyping\\$[[Γ ; Θ ⊨ uN ≤ iM ⫤ SC]]$\\(\cref{sec:subtyping})};
    \node[below of=1] (3) {Positive Subtyping\\$[[Γ ; Θ ⊨ uP ≥ iQ ⫤ SC]]$\\(\cref{sec:subtyping})};
    \node[left=1cm of 3] (2) {Subtyping Constraint Merge\\$[[Θ ⊢ SC1 & SC2 = SC3]]$\\(\cref{sec:constraint-merge})};
    \node[right=1.4cm of 3] (5) {Unification\\ $[[Γ ; Θ ⊨ uN ≈u iM ⫤ UC]]$\\ $[[Γ ; Θ ⊨ uP ≈u iQ ⫤ UC]]$\\(\cref{sec:unification})};
    \node[below of=3] (4) {Upgrade\\$[[upgrade Γ ⊢ iP to Δ = iQ]]$\\(\cref{sec:lub})};
    \node[below of=2] (6) {Least Upper Bound\\$[[Γ ⊨ iP1 ∨ iP2 = iQ]]$\\(\cref{sec:lub})};
    \node[below of=6] (7) {Anti-Unification\\$[[Γ ⊨ iP1 ≈au iP2 ⫤ ( Ξ , uQ , aus1 , aus2 )]]$\\$[[Γ ⊨ iN1 ≈au iN2 ⫤ ( Ξ , uM , aus1 , aus2 )]]$\\(\cref{sec:antiunification})};
    \node[below of=5] (8) {Unification Constraint Merge\\$[[Θ ⊢ UC1 & UC2 = UC3]]$\\(\cref{sec:constraint-merge})};
    
    % Define edges
    \draw[->] (1) to (2);
    \draw[->] (1) to (3);
    \draw[->] (1) to (5);
    \draw[->] (2) to (3);
    \draw[->] (2) to (6);
    \draw[->] (3) to (4);
    \draw[->] (3) to (5);
    \draw[->] (4) to (6);
    \draw[->] (5) to (8);
    \draw[->] (6) to (7);
  \end{tikzpicture}  
  \caption{Dependency graph of the subtyping algorithm}
  \label{fig:subtyping-algo}
\end{figure}

\subsection{Subtyping}
\label{sec:subtyping}

Now, we present the subtyping algorithm itself.
Although the algorithm is presented as a single procedure,
is important for the structure of the proof that the positive subtyping algorithm
does not invoke the negative one. This way, the correctness of the positive 
subtyping will be proved independently and used afterwards to prove the
correctness of the negative subtyping.


\begin{algorithm}[Subtyping]
  \label{alg:subtyping}
  \hfill\\
  \ottdefnANsub{}
  \ottdefnAPsup{}
\end{algorithm}

The inputs of the subtyping algorithm are the declarative context $[[Γ]]$,
the subtyping context $[[Θ]]$ (it specifies in which contexts the algorithmic variables
must be instantiated), and the types themselves: $[[uN]]$ and $[[iM]]$ for the negative case,
and $[[uP]]$ and $[[iQ]]$ for the positive case. 
As one of the invariants, we require
$[[iM]]$ and $[[iQ]]$ to be declarative (i.e. not containing algorithmic variables).
The output of the algorithm is a set of \emph{subtyping constraints} $[[SC]]$,
which will be discussed in the next section.

Let us overview the inference rules of the subtyping algorithm.
\begin{itemize}
  \item \ruleref{\ottdruleANVarLabel} and \ruleref{\ottdruleAPVarLabel} 
    are the base cases. They copy the corresponding declarative rules and
    ensure reflexivity.
  \item \ruleref{\ottdruleAPUVarLabel} is the only case generating 
    subtyping constraints. In this case, we must ensure
    that the resulting constraints guarantee that the instantiation of 
    $[[â⁺]]$ is a supertype of $[[iP]]$.
    However, the obvious constraint $[[â⁺ :≥ iP]]$ might be problematic
    if  $[[iP]]$ is not well-formed in $[[Θ(â⁺)]]$. For this reason,
    we use the \emph{upgrade} procedure (it will be covered in \cref{sec:lub})
    to find the minimal supertype of $[[iP]]$, which is well-formed in $[[Θ(â⁺)]]$. 

    Notice that this rule does not have a negative counterpart. This is
    because one of the important invariants of the algorithm: 
    in the negative subtyping, only positive algorithmic variables
    can occur in the types. 
    
  \item \ruleref{\ottdruleAShiftDLabel} and \ruleref{\ottdruleAShiftULabel} are the
    \emph{shift} rules. According to the declarative system,
    shifted subtyping requires equivalence. In the presence of the algorithmic 
    variables, it means that the left and the right-hand sides of the subtyping
    must be unified. Hence, the shift rules invoke the unification algorithm, 
    which will be discussed in \cref{sec:unification}. The unification 
    returns the minimal set of constraints $[[UC]]$, which is necessary
    and sufficient for the subtyping. 

  \item \ruleref{\ottdruleAArrowLabel}.
    In this case, the algorithm makes two calls:
    a recursive call to the negative subtyping algorithm for the argument types,
    and a call to the positive subtyping algorithm for the result types.
    After that, the resulting constraints are merged using the
    \emph{subtyping constraint merge} procedure, 
    which is discussed in \cref{sec:constraint-merge}.
  \item \ruleref{\ottdruleAForallLabel} and \ruleref{\ottdruleAExistsLabel}
    are symmetric. These are the only places where 
    the algorithmic variables are introduced.
    It is done by algorithmization (\cref{sec:variable-algorithmization}) 
    of the quantified variables: these variables are replaced by 
    fresh algorithmic variables in the body of the quantified type,
    the algorithmic variables are added to the subtyping context $[[Θ]]$,
    after that, the recursive call is made. Notice that the declarative context
    $[[Γ]]$ is extended by the quantified variables from the right-hand side,
    which matches the declarative system.
\end{itemize}


Then soundness lemma (\cref{lemma:pos-subt-soundness,lemma:neg-subt-soundness}) 
and completeness (\cref{lemma:pos-subt-completeness,lemma:neg-subt-completeness})
of the algorithm together give us the following simplified theorem:

\begin{theorempreview}[Correctness of subtyping algorithm]
  \hfill
  \begin{itemize}
    \item [$-$]  $[[ Γ ; · ⊨ uN ≤ iM ⫤ · ]]$ is equivalent to $[[ Γ ⊢ iN ≤ iM ]]$;
    \item [$+$] $[[ Γ ; · ⊨ uP ≥ iQ ⫤ · ]]$ is equivalent to $[[ Γ ⊢ iP ≥ iQ ]]$.
  \end{itemize}
\end{theorempreview}


\subsection{Constraints}

Unification and subtyping algorithms are based on constraint generation.
The constraints are represented by a set of constraint entries.

\begin{definition}[Unification Constraint]
  \hfill
  \begin{description}
    \item[unification entry] (denoted as $[[ucE]]$) is an expression of shape 
      $[[pua :≈ iP]]$ or $[[nua :≈ iN]]$;
    \item[unification constraint] (denoted as $[[UC]]$) is a set of 
      unification constraint entries.
      We denote $\{[[α̂±]] \mid [[ucE ∊ UC]] \text{ restricting $[[α̂±]]$ }\}$ 
      as $[[dom(UC)]]$.
  \end{description}
\end{definition}

However, in the subtyping, we need to consider more general
kind of constraints. Specifically,
subtyping constraint entries can restrict a variable
not only to be equivalent to a certain type, but
also to be a supertype of a positive type.

\begin{definition}[Subtyping Constraint]
  \hfill
  \begin{description}
    \item[subtyping entry] (denoted as $[[scE]]$) is an expression of shape 
      $[[pua :≥ iP]]$, $[[nua :≈ iN]]$, or $[[pua :≈ iP]]$;
    \item[subtyping constraint] (denoted as $[[SC]]$) is a set of subtyping constraint entries.
      We denote $\{[[α̂±]] \mid [[scE ∊ SC]] \text{ restricting $[[α̂±]]$ }\}$ 
      as $[[dom(SC)]]$.
  \end{description}
\end{definition}

\begin{definition}[Well-formed Constraint Entry]
  We say that a constraint entry is well-formed in a context $[[Γ]]$ if
  its associated type is well-formed in $[[Γ]]$.
  \begin{itemize}
    \item[] $[[Γ ⊢ pua :≥ iP]]$ ~iff~ $[[Γ ⊢ iP]]$;
    \item[] $[[Γ ⊢ pua :≈ iP]]$ ~iff~ $[[Γ ⊢ iP]]$;
    \item[] $[[Γ ⊢ nua :≈ iN]]$ ~iff~ $[[Γ ⊢ iN]]$.
  \end{itemize}
\end{definition}


\begin{definition}[Well-formed Constraint]
  We say that a constraint is well-formed in a
  subtyping context $[[Θ]]$ if all its entries are well-formed in
  the corresponding elements of $[[Θ]]$.
  More formally, 
  $[[Θ ⊢ SC]]$ holds iff for every $[[scE]] \in $ $[[SC]]$,
  such that $[[scE]]$ restricts $[[α̂±]]$,
  we have $[[Θ(α̂±) ⊢ scE]]$.

  We write $[[Θ ⊢ SC : Ξ]]$ to denote
  that $[[Θ ⊢ SC]]$ and $[[dom(SC) = Ξ]]$.

  $[[Θ ⊢ UC]]$ and $[[Θ ⊢ UC : Ξ]]$ are defined analogously.
\end{definition}


\subsubsection{Constraint Satisfaction}

A constraint entry restricts a type that can be assigned to a variable.
We say that a type satisfies a constraint entry if it can be assigned
to the variable restricted by the entry.

\begin{definition}[Type Satisfying a Constraint Entry]
  \hfill\\
  \begin{multicols}{2}
  \ottdefnSATSCEN{}
  \columnbreak\\
  \ottdefnSATSCEP{}
  \end{multicols}
\end{definition}

We say that a substitution satisfies a constraint---a set of constraint 
entries if each entry is satisfied by the type assigned to the variable
by the substitution. 

\begin{definition}[Substitution Satisfying a Constraint]
  We write $[[Θ ⊢ uσ : SC]]$ to denote that
  a substitution $[[uσ]]$ satisfies a constraint $[[SC]]$ in a context $[[Θ]]$.
  It presumes that $[[Θ ⊢ SC]]$ and 
   means that for any $[[ucE]] \in [[SC]]$, if $[[ucE]]$ restricts $[[α̂±]]$,
  then $[[Θ(α̂±) ⊢ [uσ]α̂± : ucE]]$.


  Unification constraint satisfaction $[[Θ ⊢ uσ : UC]]$ 
  is defined analogously as a special case of subtyping constraint satisfaction.

\end{definition}


Notice that $[[Θ ⊢ uσ : SC]]$ does not 
imply the signature $[[Θ ⊢ uσ : dom(SC)]]$, because 
the latter also specifies $[[uσ]]$ outside of the domain $[[dom(SC)]]$
(see \cref{def:algo-subst-sig}).


\subsubsection{Constraint Merge}
\label{sec:constraint-merge}

In this section, define the least upper bound 
for constraints, which we call \emph{merge}.
Intuitively, the merge of two constraints is the least
constraint such that any substitution satisfying both constraints
satisfies the merge as well.
First, we define the merge of entries,
and then extend it to the set of entries.

\begin{definition} [Matching Entries]
  We call two unification constraint entries 
  or two subtyping constraint entries matching 
  if they are restricting the same unification variable.
\end{definition}

Two matching entries formed in the same context $[[Γ]]$ 
can be merged in the following way:
\begin{algorithm}[Merge of Matching Constraint Entries]
  \label{definition:merge-matching-entries}
   \hfill 

  \ottdefnSCME\\
\end{algorithm}

\begin{itemize}
  \item \ruleref{\ottdruleSCMEPEqEqLabel} and \ruleref{\ottdruleSCMENEqEqLabel}
    are symmetric cases. To merge two matching entries restricting
    a variable to be equivalent to certain types, we check
    that these types are equivalent to each other.
    To do so, it suffices to check for \emph{equality} of their normal forms,
    as discussed in \cref{sec:equivalence-normalization}. 
    After that, we return the left-hand entry.

  \item \ruleref{\ottdruleSCMEEqSupLabel} and \ruleref{\ottdruleSCMESupEqLabel}
    are also symmetric. 
    In this case,
    since one of the entries requires the variable to be equal to 
    a type, the resulting entry must also imply that.
    However, for the soundness, it is needed to ensure that
    the equating restriction is stronger than the subtyping restriction.
    For this purpose, the premise invokes the positive subtyping.

  \item \ruleref{\ottdruleSCMESupSupLabel} 
    In this case, we find the least upper bound of the types from the input
    restrictions, 
    and as the output, restrict the variable to be a supertype of the result.
    The least upper bound procedure will be discussed in \cref{sec:lub}.
\end{itemize}


Unification constraint entries are a special case of subtyping constraint
entries. They are merged using the same algorithm 
(\cref{definition:merge-matching-entries}).
Notice that the merge of two matching unification constraint entries
is a unification constraint entry.
\begin{lemma}[Merge of Matching Unification Constraint Entries is well-defined]
  \label{lemma:merge-matching-entries-welldef}
  Suppose that $[[Γ ⊢ ucE1]]$ and $[[Γ ⊢ ucE2]]$
  are unification constraint entries. 
  Then the merge of $[[ucE1]]$ and $[[ucE2]]$ 
  $[[Γ ⊢ ucE1 & ucE2 = ucE]]$
  according to \cref{definition:merge-matching-entries},
  is a unification constraint entry.
\end{lemma}
\begin{proof}
  Since $[[ucE1]]$ and $[[ucE2]]$ are matching unification constraint entries,
  they have the shape $([[pua :≈ iP1]], [[pua :≈ iP2]])$ or
  $([[nua :≈ iN1]], [[nua :≈ iN2]])$.
  Then the merge of $[[ucE1]]$ and $[[ucE2]]$ 
  can only be defined by \ruleref{\ottdruleSCMEPEqEqLabel} or
  \ruleref{\ottdruleSCMENEqEqLabel}.
  In both cases the result, if it exists, 
  is a unification constraint entry:
  in the first case, the result has shape $[[pua :≈ iP1]]$,
  in the second case, the result has shape $[[nua :≈ iN1]]$.
\end{proof}


% Notice that in case of equivalence, the assigned types
% must be equal (i.e. alpha-equivalent) to be merged. This is because
% the unification algorithm assumes that every type is normalized,
% and hence, equivalence is alpha-equivalence 
% (\cref{corollary:nf-complete-wrt-subt-equiv,corollary:nf-sound-wrt-subt-equiv}).

\begin{algorithm}[Merge of Subtyping Constraints]
  \label{definition:merge-subtyping-constraints}
  Suppose that $[[Θ ⊢ SC1]]$ and $[[Θ ⊢ SC2]]$.\\
  Then $[[Θ ⊢ SC1 & SC2 = SC]]$
  defines a set of constraints $[[SC]]$ such that $[[scE]] \in [[SC]]$ iff either:
  \begin{itemize}
    \item $[[scE]] \in [[SC1]]$ and there is no matching $[[scE']] \in [[SC2]]$; or
    \item $[[scE]] \in [[SC2]]$ and there is no matching $[[scE']] \in [[SC1]]$; or
    \item $[[Θ(α̂±) ⊢ scE1 & scE2 = scE]]$ for some $[[scE1]] \in [[SC1]]$ and $[[scE2]] \in [[SC2]]$
      such that $[[scE1]]$ and $[[scE2]]$ both restrict variable $[[α̂±]]$. 
  \end{itemize}
\end{algorithm}

Unification constraints can be considered 
as a special case of subtyping constraints,
and the merge of unification constraints
is defined as the merge of subtyping constraints.
Then it is easy to see that the merge of two 
unification constraints is a unification constraint.

\begin{lemma}[Merge of Unification Constraints is well-defined]
  Suppose that $[[Θ ⊢ UC1]]$ and $[[Θ ⊢ UC2]]$
  are unification constraints. 
  Then the merge of $[[UC1]]$ and $[[UC2]]$ 
  $[[Θ ⊢ lift UC1 & lift UC2 = lift UC]]$
  according to \cref{definition:merge-subtyping-constraints},
  is a unification constraint.
\end{lemma}
\begin{proof}
  $[[UC]]$ consists of unmatched entries of $[[UC1]]$ and $[[UC2]]$,
  which are \emph{unification} constraint entries by assumption,
  and merge of matching entries, which also are  
  \emph{unification} constraint entries by \cref{lemma:merge-matching-entries-welldef}.
\end{proof}

\Cref{lemma:merge-soundness,lemma:merge-completeness} 
show the correctness and initiality of the merge operation,
which can be expressed in the following simplified theorem:
\begin{theorempreview}[Correctness of Constraint Merge]
  A substitution $[[uσ]]$ satisfying both constraints
  $[[SC1]]$ and $[[SC2]]$ 
  if and only if it satisfies their merge.
\end{theorempreview}

The unification constraint merge satisfies the same theorem,
however, because the merge of unification constraint entries 
$[[ucE1]]$ and $[[ucE2]]$ always results in one of them, 
a stronger soundness property holds (see \cref{lemma:unif-merge-soundness}):
\begin{theorempreview}[Soundness of Unification Constraint Merge]
  If $[[Θ ⊢ UC1 & UC2 = UC]]$ then $[[UC = UC1 ∪ UC2]]$.
\end{theorempreview}

\subsection{Unification}
\label{sec:unification}

The subtyping algorithm calls the following subtask:
given two algorithmic types, we need to find the most general substitution 
for the algorithmic variables in these types, such that the resulting 
types are equivalent. This problem is known as \emph{unification}.

In our case, the unification is restricted in the following way:
first, before unifying the types, we normalize them, which 
allows us to reduce (non-trivial) equivalence to (trivial) equality;
second, we preserve invariants which guarantee that
one side of the unification is always declarative, which in fact, 
reduces the unification to the \emph{matching} problem.

The unification procedure
returns a set of minimal constraints,
that must be satisfied by a substitution
unifying the input types.

\begin{algorithm}[Unification]
  \hfill
  \begin{multicols}{2}
  \ottdefnUNUnif{}
  \columnbreak\\
  \ottdefnUPUnif{}
  \end{multicols}
\end{algorithm}


\begin{itemize}
  \item \ruleref{\ottdruleUShiftULabel}, \ruleref{\ottdruleUShiftDLabel}, 
    \ruleref{\ottdruleUForallLabel}, and \ruleref{\ottdruleUExistsLabel}
    are defined congruently. In the shift rules, the algorithm
    removes the outermost constructor. In the
    $[[∀]]$ and $[[∃]]$ rules, it removes the quantifiers,
    adding the quantified variables to the context $[[Γ]]$.
    Notice that $[[Θ]]$, which specifies
    the contexts in which the algorithmic variables must be instantiated,
    is not changed.
  \item \ruleref{\ottdruleUNVarLabel} and \ruleref{\ottdruleUPVarLabel} 
    are the base cases. 
    Since the sides are equal and free from algorithmic variables,
    the unification returns an empty constraint. 
  \item \ruleref{\ottdruleUNVarLabel} and \ruleref{\ottdruleUPVarLabel}
    are symmetric cases constructing the constraints. 
    When an algorithmic variable is unified with a type, 
    we must check that the type is well-formed in the required context,
    and if it is, we return a constraint restricting the variable
    to be equivalent to that type.
  \item \ruleref{\ottdruleUArrowLabel}.
    In this case, the algorithm makes two recursive calls:
    it unifies the arguments and the results of the arrows.
    After that, the resulting constraints are merged using the
    \emph{unification constraint merge} procedure, 
    which is discussed in \cref{sec:constraint-merge}.
    Notice that $[[UC1]]$ and $[[UC2]]$ are guaranteed to be
    \emph{unification} constraints, not arbitrary \emph{subtyping} 
    constraints: it is important for modularizing the proofs, 
    since the properties of the \emph{unification} constraint merge
    can be proved independently from the \emph{subtyping} constraint merge.
\end{itemize}

\subsection{Least Upper Bound}
\label{sec:lub}

In this section, we present
the algorithm finding the least common supertype of two positive types. 
It is used directly by the constraint merge procedure (\cref{sec:constraint-merge}),
and indirectly, through the type upgrade by positive subtyping
(\cref{sec:subtyping}). Perhaps, the least upper bound is the least 
intuitive part of the algorithm, and its correctness will be covered
in \cref{sec:alg-upper-bounds-proofs}.

\begin{algorithm}[The Least Upper Bound Algorithm]
  \hfill\\
  \ottdefnLUBNsub{}
\end{algorithm}

\begin{itemize}
  \item \ruleref{\ottdruleLUBVarLabel}
    The base case is trivial: 
    the least upper bound of to equal variables
    is the variable itself.
  \item \ruleref{\ottdruleLUBShiftLabel}
    In case both sides of the least upper bound are shifted,
    the algorithm needs to find the anti-unifier of them. 
    Intuitively, this is because in general, the upper bounds of
    $[[↓iN]]$ are $[[∃nas.iP]]$ such that 
    $[[nas]]$ can be instantiated with some $[[iMs]]$ so that
    $[[ Γ ⊢ [iMs/nas]iP ≈ ↓iN ]]$ (see \cref{lemma:shape-of-supertypes}).
  \item \ruleref{\ottdruleLUBExistsLabel}
    In this case, we move the quantified variables to the context $[[Γ]]$, 
    and make a recursive call. 
    It is important to make sure that $[[nas]]$ and $[[nbs]]$ are disjoint.
    In this case, it is guaranteed that the resulting 
    $[[fv(iQ)]]$ will be free of $[[nas]]$ and $[[nbs]]$,
    and thus, the resulting type will be a supertype of both sides
    (it will be discussed in \cref{lemma:shape-of-supertypes}).
\end{itemize}


In the positive subtyping algorithm (\cref{sec:subtyping}),
\ruleref{\ottdruleAPUVarLabel} 
generates a restriction of a variable $[[α̂⁺]]$.
On the one hand, this restriction must imply 
$[[â⁺ :≥ iP]]$ for the subtyping to hold.
On the other hand, the type used in this restriction 
must be well-formed in a potentially stronger (smaller) 
context than $[[iP]]$.

To resolve this problem, we define the \emph{upgrade} procedure,
which for given $[[Δ]]$, $[[pnas]]$, and $[[Δ, pnas ⊢ iP]]$,
finds $[[Δ ⊢ iQ]]$---the least supertype of $[[iP]]$ 
among the types well-formed in $[[Δ]]$.

The trick is to make sure that the `forbidden' variables
$[[pnas]]$ are not used explicitly in the supertypes
of $[[iP]]$. For this purpose, we
construct new types $[[iP1]]$ and $[[iP2]]$,
in each of them replacing the forbidden variables
with fresh variables $[[pnbs]]$ and $[[pncs]]$,
and then find the least upper bound of $[[iP1]]$ and $[[iP2]]$.
It turns out that this renaming forces the common types of 
$[[iP1]]$ and $[[iP2]]$ to be agnostic to $[[pnas]]$,
and thus, the supertypes of $[[iP]]$ well-formed in $[[Δ]]$
are exactly the common supertypes of $[[iP1]]$ and $[[iP2]]$.
These properties are considered in more details in \cref{sec:upgrade-lemmas}.

\begin{algorithm}[Type Upgrade]
  \hfill\\
  \ottdefnLUBUp{}
\end{algorithm}

\begin{paragraph}{Note on the Greatest Lower Bound}
  In contrast to the least upper bound, 
  the general greatest lower bound does not exist in our system.
  For instance, consider a positive type $[[iP]]$, 
  together with its non-equivalent
  supertypes $[[iP1]]$ and $[[iP2]] \not\simeq [[iP1]]$
  (for example, $[[iP = ↓↑↓γ⁻]]$, $[[iP1 = ∃α⁻.↓↑↓α⁻]]$, 
  and $[[iP2 = ∃α⁻.↓α⁻]]$).
  Then for arbitrary $[[iQ]]$ and $[[iN]]$, 
  let us consider the common subtypes of 
  $A = [[iQ → ↓↑iQ → ↓↑iQ → iN]]$ and $B = [[iP → ↓↑iP1 → ↓↑iP2 → iN]]$.
  It is easy to see that $[[∀α⁺.∀β⁺. α⁺ → ↓↑α⁺ → ↓↑β⁺ → iN]]$ and 
  $[[∀α⁺.∀β⁺. α⁺ → ↓↑β⁺ → ↓↑α⁺ → iN]]$ are
  both \emph{maximal} common subtypes of $A$ and $B$,
  and since they are not equivalent, none of them is 
  the \emph{greatest} one.

  However, we designed the subtyping system in such a way 
  that the greatest lower bound is not needed:
  the negative variables are always `protected'
  by \emph{invariant} shifts ($[[↑]]$ and $[[↓]]$), 
  and thus, the algorithm can only require
  a substitution of a negative variable to be 
  \emph{equivalent} to some type but never 
  to be a \emph{subtype}.
\end{paragraph}

\subsection{Anti-unification}
\label{sec:antiunification}

Next, we define the anti-unification procedure,
also known as the \emph{most specific generalization}.
As an input, it takes two declarative types
(e.g., in the positive case $[[iP1]]$ and $[[iP2]]$)
and a context $[[Γ]]$.
and returns a type $[[uQ]]$---the generalizer,
containing negative placeholders 
(represented by algorithmic variables) from 
$[[Ξ]]$ and two substitutions $[[uτ1]]$ and $[[uτ2]]$.
The substitutions replace the placeholders with 
declarative types well-formed in $[[Γ]]$,
such that $[[ [uτ1]uQ = iP1 ]]$ and $[[ [uτ2]uQ = iP2 ]]$.
Moreover, the algorithm guarantees that 
$[[uQ]]$ is the most specific type with this property: 
any other generalizer can be turned into $[[uQ]]$ by some substitution
$[[uρ]]$.

It is important to note the differences between 
the standard anti-unification and our version.
First, we only allow the placeholders at \emph{negative} positions,
which means, for example, that $[[α⁺]]$ and $[[β⁺]]$ cannot be
generalized. Second, the generated pair of substitutions 
$[[uτ1]]$ and $[[uτ2]]$ must replace the placeholders with 
types well-formed in a specified context $[[Γ]]$.

The anti-unification algorithm assumes that the input types 
are normalized. This way, anti-unification up-to-equality rather than 
 anti-unification up-to-equivalence is sufficient.

\begin{algorithm}[Anti-unification]
  \hfill
  
  \ottdefnAUAUP{}
  \ottdefnAUAUN{}

\end{algorithm}

\begin{itemize}
  \item \ruleref{\ottdruleAUPVarLabel} and \ruleref{\ottdruleAUNVarLabel}
    are the base cases. 
    In this case, since the input types are equal, 
    the algorithm returns this type as a generalizer,
    without generating any placeholders.

  \item \ruleref{\ottdruleAUShiftDLabel}, \ruleref{\ottdruleAUShiftULabel},
    \ruleref{\ottdruleAUForallLabel}, and \ruleref{\ottdruleAUExistsLabel}
    are defined congruently. In the shift rules, the algorithm
    removes the outermost constructor. In the
    $[[∀]]$ and $[[∃]]$ rules, it removes the quantifiers.
    Notice that the algorithm does not add the removed variables to
    the context $[[Γ]]$. This is because $[[Γ]]$
    is used to restrict the resulting anti-unification substitutions, 
    and is fixed throughout the algorithm.

  \item \ruleref{\ottdruleAUAULabel} is the most important rule, 
    since it generates the placeholders. 
    This rule only applies if other negative rules failed.
    Because of that, the anti-unification procedure is 
    \emph{not} syntax-directed. 

    The generated placeholder is indexed with a pair of 
    types it is mapped to. It allows the algorithm to 
    automatically unite the anti-unification solutions 
    generated by the different branches of 
    \ruleref{\ottdruleAUArrowLabel}.

    Notice that this rule does not have a positive counterpart,
    since we only allow negative placeholders.

  \item \ruleref{\ottdruleAUArrowLabel}
    makes two recursive calls to the anti-unification procedure,
    and unites the results. Suppose that
    $[[uτ1]]$  and $[[uτ2]]$ are the substitutions generated by
    anti-unification of \emph{argument} types of the arrow,
    and $[[uτ1']]$ and $[[uτ2']]$ are the substitutions generated by 
    anti-unification of \emph{result} types of the arrow.
    It is important that if ($[[uτ1]]$, $[[uτ2]]$)
    and ($[[uτ1']]$, $[[uτ2']]$) send some variables to the same pair of types,
    i.e., $[[ [uτ1]α̂⁻ = [uτ1']β̂⁻]]$ and $[[ [uτ2]α̂⁻ = [uτ2']β̂⁻]]$,
    then these variables are equal, i.e., $[[α̂⁻ = β̂⁻]]$.
    This property is guaranteed by \ruleref{\ottdruleAUAULabel}:
    the name of the placeholder is determined by the pair of 
    types it is mapped to.
\end{itemize}

\newpage

\section{Declarative Typing}

In the previous section, we presented the 
type system together with subtyping specification 
and the algorithm. In this section, 
we describe the language under this type system, 
together with the type inference specification
and algorithm.  

\subsection{Grammar}

First, we define the syntax of the language.
The language combines System F with call-by-push-value 
style. 
\begin{definition}[Language Grammar]
  \hfill
  \begin{multicols}{2}
    \ottgrammartabular{
      \ottc\ottinterrule
    }

    \ottgrammartabular{
      \ottv\ottinterrule
    }
  \end{multicols}
\end{definition}
Notice that the language does not have
first-class applications: instead, 
we use applicative let bindings---
constructions that bind a result of
a fully applied function to a (positive) 
variable.
In the call-by-push-value paradigm, 
it corresponds to monadic bind or do-notation. 
Typewise, these let-binders come in two forms:
annotated and unannotated. The annotated let-binders
$[[let x:iP = v(args); c]]$ 
requires the application to infer the annotated
$[[iP]]$, whereas the unannotated 
$[[let x = v(args); c]]$ 
is used when the inferred type is unique. 

A computation of a polymorphic type is constructed 
using $[[Λα⁺ . c]]$, however, the elimination of $[[∀]]$
is implicit. Conversely, the existential types
are constructed implicitly and eliminated 
using the standard unpack mechanism:
$[[let∃ (nas, x) = v; c]]$.

Another dual pair of constructions are 
$[[return v]]$ and $[[{c}]]$. 
The former allows us to embed a value in pure 
computations. The latter, on the contrary,
encapsulates a thunk of computation in a value. 

Finally, the language has several standard constructions:
lambda-abstractions $[[λx:iP.c]]$,
standard let-bindings $[[let x = v; c]]$,
and type annotations that can be added to any value or computation:
$[[(v:iP)]]$ and $[[(c:iN)]]$.

\subsection{Declarative Type Inference}

Next, we define the specification of the type 
inference for our language. First, we introduce 
variable context specifying the types of variables 
in the scope of the current rule. 

\begin{definition}[Variable Context]
  The variable typing context $[[Φ]]$
  is represented by a set of entries of the form
  $[[x : iP]]$. 
\end{definition}

The specification is represented by an inference system of
three mutually recursive judgments:
positive inference $[[Γ ; Φ ⊢ v : iP]]$,
negative type inference $[[Γ ; Φ ⊢ c : iN]]$, and
application type inference $[[Γ ; Φ ⊢ iN ● args ⇒> iM ]]$.
In the premises, the inference rules also refer to 
the declarative subtyping (\cref{def:subDOne}),
type well-formedness (\cref{alg:wf}), 
and normalization (\cref{alg:type-nf}).
\begin{itemize}
  \item $[[Γ ; Φ ⊢ v : iP]]$ (and symmetrically, $[[Γ ; Φ ⊢ c : iN]]$)
    means that under the type context $[[Γ]]$ and
    the variable context $[[Φ]]$, for the value $[[v]]$,
    type $[[iP]]$ is inferrable. It guarantees that 
    $[[v]]$ is well-formed in $[[Γ]]$ and $[[Φ]]$ in
    the standard sense.
  \item $[[ Γ ; Φ ⊢ iN ● args ⇒> iM ]]$ is the application type inference 
    judgment. It means that if a head of type $[[iN]]$ 
    is applied to list of values $[[args]]$, 
    then the resulting computation can be typed as $[[iM]]$.
\end{itemize}

\begin{definition}[Declarative Type Inference]
  \label{def:declarative-typing}
  \hfill
  \begin{multicols}{2}
  \ottdefnDTNInf{}
  \ottdefnDTPInf{}
  \ottdefnDTSpinInf{}
  \end{multicols}
\end{definition}

Let us discuss selected rules of the declarative system:
\begin{itemize}
  \item \ruleref{\ottdruleDTVarLabel}
    says that the type of a variable is inferred from the context.
  \item \ruleref{\ottdruleDTThunkLabel} says
    that the type of a thunk is inferred by shifting up the type of the 
    contained computation. Symmetrically, \ruleref{\ottdruleDTReturnLabel}
    infers the type of a return by shifting down the type of the
    contained value.
  \item \ruleref{\ottdruleDTPAnnotLabel} and \ruleref{\ottdruleDTNAnnotLabel} are symmetric.
    They allow the inferred type to be refined by annotating it with a supertype.
  \item \ruleref{\ottdruleDTNEquivLabel} and \ruleref{\ottdruleDTPEquivLabel}
    mean that th declarative system allows to infer any type from the equivalence class.
  \item \ruleref{\ottdruleDTUnpackLabel} is standard for existential types,
    and its first premise inferring the existential type of the value being unpacked.
    It is important however that the inferred existential type is normalized. 
    This is because there might be multiple equivalent existential types 
    with different order or even number of quantified variables, 
    and to bind them, the algorithm needs to fix the canonical one.
  \item \ruleref{\ottdruleDTAppLetAnnLabel} allows us to accommodate the applications
    with annotated let-bindings. The first premise infers the type of the head of the application,
    which must be a thunked computation. Then if after applying it 
    to the arguments, the resulting type can be equated to the annotated one,
    we infer the body of the let-binding in the context extended with the bound variable.
  \item \ruleref{\ottdruleDTAppLetLabel} is similar to \ruleref{\ottdruleDTAppLetAnnLabel},
    but it is used when the type of the application is unique, and thus, the annotation
    is redundant. Here $[[Γ ; Φ ⊢ iM ● args ⇒> ↑iQ uniq]]$ means that
    if also $[[Γ ; Φ ⊢ iM ● args ⇒> ↑iQ']]$ then $[[Γ ⊢ iQ ≈ iQ']]$
\end{itemize}

Let us discuss the rules of the application inference:
\begin{itemize}
  \item \ruleref{\ottdruleDTEmptyAppLabel} 
    is the base case. If the list of arguments is empty, 
    the inferred type is the type of the head. 
    However, we relax this specification by allowing it to 
    infer any other equivalent type. 
    The relaxation of this rule is enough to guarantee 
    this property for the whole judgement:
    if $[[Γ ; Φ ⊢ iN ● args ⇒> iM]]$ then 
    $[[Γ ; Φ ⊢ iN ● args ⇒> iM']]$ for any equivalent 
    $[[iM']]$.
  \item \ruleref{\ottdruleDTArrowAppLabel}
    is where the application type is inferred: 
    if the head has an arrow type $[[iQ → iN]]$,
     we are allowed to apply it as soon as 
    as soon as the first argument has a type, which is a subtype of $[[iQ]]$.
  \item \ruleref{\ottdruleDTForallAppLabel}
    is the rule ensuring the implicit elimination of the universal quantifiers. 
    If we are applying a polymorphic computation, 
    we can instantiate its quantified variables with any types,
    which is expressed by the substitution $[[Γ ⊢ σ : {pas}]]$.
\end{itemize}



\section{Algorithmic Typing}

Next, we present the type inference algorithm, 
which is sound and complete with respect to the declarative specification
(\cref{def:declarative-typing}).

\subsection{Algorithmic Type Inference}

Mirroring the declarative typing, 
the algorithm is represented by an inference system of three mutually recursive
judgments:
\begin{itemize}
  \item $[[Γ ; Φ ⊨ v : iP]]$ and  $[[Γ ; Φ ⊨ c : iN]]$
    are the algorithmic versions of $[[Γ ; Φ ⊢ v : iP]]$ and $[[Γ ; Φ ⊢ c : iN]]$.
    In contrast with the declarative counterparts, they are deterministic,
    and guarantee that the inferred type is normalized. 
  \item $[[Γ ; Φ ; Θ1 ⊨ uN ● args ⇒> uM ⫤ Θ2 ; SC]]$
    is the algorithmization of $[[Γ ; Φ ⊢ iN ● args ⇒> iM]]$.
    Notice that $[[uN]]$ contains algorithmic variables, 
    which are specified by the context $[[Θ1]]$.
    Moreover, the inferred type $[[uM]]$ is also algorithmic,
    and can have several non-equivalent instantiations. To accommodate that, 
    the algorithm also returns $[[Θ2]]$ and $[[SC]]$ specifying 
    the variables used in $[[uM]]$: $[[Θ2]]$ defines the contexts
    in which the variables must be instantiated, and $[[SC]]$
    imposes restrictions on the variables. 
\end{itemize}
As subroutines, the algorithm calls
subtyping (\cref{alg:subtyping}),
type well-formedness (\cref{alg:wf}),
constraint merge (\cref{sec:constraint-merge}),
normalization (\cref{alg:type-nf}),
and constraint singularity which will be defined later in 
\cref{sec:constraint-singularity}.
It also relies on basic set operations and the ability to 
deterministically choose fresh variables.

\begin{algorithm}
  \hfill\\
  \ottdefnATNInf{}
  \ottdefnATPInf{}
  \ottdefnATSpinInf{}
\end{algorithm}

Let us discuss the inference rules of the algorithm:
\begin{itemize}
  \item \ruleref{\ottdruleATVarLabel} 
    infers the type of a variable by looking it up in the context
    and normalizing the result.
  \item \ruleref{\ottdruleATThunkLabel} and \ruleref{\ottdruleATReturnLabel}
    are similar to the declarative rules: they make a recursive call
    to type the body of the thunk or the return expression and
    put the shift on top of the result.
  \item \ruleref{\ottdruleATPAnnotLabel} and \ruleref{\ottdruleATNAnnotLabel}
    are symmetric. They make a recursive call to infer the type of the annotated
    expression, check that the inferred type is a subtype of the annotation,
    and return the normalized annotation.
  \item \ruleref{\ottdruleATtLamLabel} infers the type of a lambda-abstraction.
    It makes a recursive call to infer the type of the body in the extended context,
    and returns the corresponding arrow type. Notice that the algorithm also
    normalizes the result, which is because the annotation type $[[iP]]$
    is allowed to be non-normalized.
  \item \ruleref{\ottdruleATTLamLabel} infers the type of a big lambda.
    Similarly to the previous case, it makes a recursive call to infer the type
    of the body in the extended \emph{type} context. 
    After that, it returns the corresponding universal type. 
    It is also required to normalize the result, because, 
    for instance, $[[α⁺]]$ might not occur in the body of the lambda,
    in which case the $[[∀]]$ must be removed. 
  \item \ruleref{\ottdruleATVarLetLabel} is defined in a standard way:
    it makes a recursive call to infer the type of the bound value,
    and then returns the type of the body in the extended context.
  \item \ruleref{\ottdruleATAppLetAnnLabel}
    is interpreted as follows.
    First, it infers the type of the head of the application,
    ensuring that it is a thunked computation $[[↓iM]]$;
    after that, it makes a recursive call
    to the application inference procedure,
    which returns the algorithmic type, whose
    instantiation to a declarative type must be associated with the bound variable 
    $[[x]]$; then premise $[[Γ; Θ ⊨ ↑uQ ≤ ↑iP ⫤ SC2]]$
    together with $[[Θ ⊢ SC1 & SC2 = SC]]$
    check whether the instantiation to the annotated type $[[iP]]$ is possible,
    and if it is, the algorithm infers the type of the body in the extended context,
    and returns it as the result. 
  \item \ruleref{\ottdruleATAppLetAnnLabel}
    works similarly to \ruleref{\ottdruleATAppLetAnnLabel},
    However, since there is no annotation, 
    instead of checking the instantiation to it, 
    the algorithm checks that the inferred type
    $[[↑uQ]]$ is unique.
    It is the case if all the algorithmic variables of 
    $[[↑uQ]]$ are sufficiently restricted by $[[SC]]$,
    which is checked by the combination of
    $[[uv uQ = dom(SC)]]$ and $[[SC singular with uσ]]$.
    Together, these two premises guarantee that the only 
    possible instantiation of $[[↑uQ]]$ is $[[ [uσ]uQ ]]$.
  \item \ruleref{\ottdruleATUnpackLabel}
    works in the expected way. First, it infers the 
    existential type $[[∃nas.iP]]$ of the value being unpacked,
    and since the type is guaranteed to be normalized, binds 
    the quantified variables with $[[nas]]$.
    Then it infers the type of the body in the appropriately extended context,
    and checks that the inferred type does not depend on $[[nas]]$
    by checking well-formedness $[[Γ ⊢ iN]]$.
\end{itemize}

Finally, let us discuss the algorithmic rules of the application inference:
\begin{itemize}
  \item \ruleref{\ottdruleATEmptyAppLabel}
    is the base case. If the list of arguments is empty, 
    the inferred type is the type of the head,
    and the algorithm returns it after normalizing.
  \item \ruleref{\ottdruleATArrowAppLabel}
    is the main rule of algorithmic application inference.
    If the head has an arrow type $[[uQ → uN]]$,
    we find $[[SC1]]$---the minimal constraint ensuring that 
    $[[uQ]]$ is a supertype of the first argument's type.
    Then we make a recursive call applying $[[uN]]$ to the rest of the arguments,
    and merge the resulting constraint with $[[SC1]]$
  \item \ruleref{\ottdruleATForallAppLabel},
    analogously to the declarative case,
    is the rule ensuring the implicit elimination of the universal quantifiers. 
    This is the place where the algorithmic variables are generated.
    The algorithm simply replaces the quantified variables 
    $[[pas]]$ with fresh algorithmic variables $[[puas]]$,
    and makes a recursive call in the extended context. 
\end{itemize}

The correctness of the algorithm consists of its soundness and 
completeness, which is by mutual
induction in \cref{lemma:typing-soundness,lemma:typing-completeness}.
The simplified result is the following.
\begin{theorempreview}
  \hfill
  \begin{itemize}
    \item [$-$] $[[Γ; Φ ⊨ c : iN]]$ implies $[[Γ; Φ ⊢ c : iN]]$, 
      and $[[Γ; Φ ⊢ c : iN]]$ implies $[[Γ; Φ ⊨ c : nf(iN)]]$;
    \item [$+$] $[[Γ; Φ ⊨ v : iP]]$ implies $[[Γ; Φ ⊢ v : iP]]$, 
      and $[[Γ; Φ ⊢ v : iP]]$ implies $[[Γ; Φ ⊨ v : nf(iP)]]$.
  \end{itemize}
\end{theorempreview}


\subsection{Constraint Singularity}
\label{sec:constraint-singularity}

The singularity algorithm used in  \ruleref{\ottdruleATAppLetAnnLabel}
of the algorithmic typing check whether the constraint $[[SC]]$
is uniquely defines a substitution satisfying it, and if it does
returns such a substitution as the result.
To do that, we define a partial function $[[SC singular with uσ]]$,
taking a subtyping constraint $[[SC]]$ and returning a substitution 
$[[uσ]]$---the only possible solution of $[[SC]]$. 

First, we define the notion of singularity on constraint entries. 
$[[scE singular with iP]]$ and $[[scE singular with iN]]$
are considered partial functions taking a constraint entry $[[scE]]$
and returning the type satisfying $[[scE]]$ if such a type is unique. 

\begin{algorithm}[Singular Constraint Entry]
  \hfill\\
  \ottdefnSINGscEP{}
  \ottdefnSINGscEN{}
\end{algorithm}

\begin{itemize}
  \item \ruleref{\ottdruleSINGNEqLabel} and \ruleref{\ottdruleSINGPEqLabel} 
    are symmetric. If the constraint entry says that a variable must be equivalent to 
    a type $T$, then it is evidently singular, and the only (up-to-equivalence) type
    instantiating this variable could be $T$. This way, we return its normal form. 
  \item \ruleref{\ottdruleSINGSupVarLabel}
    implies that the only (normalized) solution of $[[pua :≥ ∃nas.pa]]$ is 
    $[[pa]]$ (it will be shown in \cref{lemma:var-subt}).
  \item \ruleref{\ottdruleSINGSupShiftLabel}
    is perhaps the least obvious rule.
    In type $[[∃nas.↓iN]]$, if $[[iN]]$ is anything different (non-equivalent) to 
    $[[nai ∊ {nas}]]$, there are at least 
    one proper supertype of $[[∃nas.↓iN]]$, since $[[iN]]$ can be abstracted over
    by an existential quantifier. Otherwise, any supertype of $[[∃nas.↓nai]]$
    is equivalent to it, and thus, the solution is unique. 
\end{itemize}

Next, we extrapolate the singularity function on constraints---sets of constraint entries. 
We require $[[SC]]$ to be a set of singular constraints, and the resulting substitution
sends each variable from $[[dom(SC)]]$ to the unique type satisfying the corresponding constraint.

\begin{algorithm}
  $[[SC singular with uσ]]$
  means that 
  \begin{enumerate}
    \item for any positive $[[scE ∊ SC]]$,
      there exists $[[iP]]$ such that $[[scE singular with iP]]$, 
      and for any negative $[[scE ∊ SC]]$,
      there exists $[[iN]]$ such that $[[scE singular with iN]]$;
    \item $[[uσ]]$ is defined as follows:
      $$
      [[ [uσ]β̂⁺ ]]  = 
          \begin{cases}
              [[ iP ]] & \text{if there is } [[scE]] \in [[dom(SC)]] \text{ restricting } [[β̂⁺]] 
                         \text{ and } [[scE singular with iP]] \\
              [[ β̂⁺ ]] & \text{otherwise}  \\
          \end{cases}
      $$
      $$
      [[ [uσ]β̂⁻ ]]  = 
          \begin{cases}
              [[ iN ]] & \text{if there is } [[scE]] \in [[dom(SC)]] \text{ restricting } [[β̂⁻]] 
                         \text{ and } [[scE singular with iN]]\\
              [[ β̂⁻ ]] & \text{otherwise}  \\
          \end{cases}
      $$
  \end{enumerate} 
\end{algorithm}

The correctness of the singularity algorithm is formulated as follows:
\begin{theorempreview}
  Suppose that $[[SC]]$ is a subtyping constraint.
  Then $[[SC singular with uσ]]$ holds if and only if 
  $[[uσ]]$ is the only (up-to-equivalence on $[[dom(SC)]]$) 
  normalized substitution satisfying $[[SC]]$.
\end{theorempreview}


\newpage

\section{Properties of the Declarative Type System}

\subsection{Type Well-formedness}
\input{\genDir/tex/wf-lemmas.tex}

\subsection{Substitution}
\input{\genDir/tex/subst-lemmas.tex}

\subsection{Declarative Subtyping}
\input{\genDir/tex/decl-subtyping-lemmas.tex}

\subsection{Equivalence}
\label{sec:decl-equiv-lemmas}
\input{\genDir/tex/equiv-lemmas.tex}

\subsection{Variable Ordering}
\input{\genDir/tex/ord-lemmas.tex}


\subsection{Normaliztaion}
\input{\genDir/tex/norm-lemmas.tex}


\section{Properties of the Algorithmic Type System}

\subsection{Algorithmic Type Well-formedness}
\input{\genDir/tex/wf-algo-lemmas.tex}

\subsection{Substitution}
\input{\genDir/tex/subst-algo-lemmas.tex}

\subsection{Normalization}
\input{\genDir/tex/norm-alg-lemmas.tex}

\subsection{Equivalence}
\input{\genDir/tex/equiv-alg-lemmas.tex}

\subsection{Unification Constraint Merge}
\input{\genDir/tex/unif-constraint-merge-lemmas.tex}

\subsection{Unification}
\input{\genDir/tex/unification-lemmas.tex}\

\subsection{Anti-unification}
\input{\genDir/tex/au-lemmas.tex}

\subsection{Upper Bounds}
\label{sec:alg-upper-bounds-proofs}
\input{\genDir/tex/lub-lemmas.tex}

\subsection{Upgrade}
\label{sec:upgrade-lemmas}
\input{\genDir/tex/upgrade-lemmas.tex}

\subsection{Constraint Satisfaction}
\input{\genDir/tex/constraint-sat-lemmas.tex}

\subsection{Positive Subtyping}
\input{\genDir/tex/alg-pos-subtyping-lemmas.tex}

\subsection{Subtyping Constraint Merge}
\input{\genDir/tex/constraint-merge-lemmas.tex}

\subsection{Negative Subtyping}
\input{\genDir/tex/alg-neg-subtyping-lemmas.tex}




\section{Properties of the Declarative Typing}
\input{\genDir/tex/decl-typing-lemmas.tex}




\section{Properties of the Algorithmic Typing}

\subsection{Singularity}
\input{\genDir/tex/singularity-lemmas.tex}

\subsection{Correctness of the Typing Algorithm}
\input{\genDir/tex/alg-typing-lemmas.tex}

\printbibliography

\end{document}
